"""
RAG ç´¢å¼•æ§‹å»ºä¸»ç¨‹å¼
æ§‹å»ºå‘é‡è³‡æ–™åº«ç´¢å¼•ä»¥æ”¯æ´æª¢ç´¢å¢å¼·ç”Ÿæˆ
"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.rag.build_index import build_chroma_index, build_simple_index
from src.utils.config_loader import ConfigLoader
import argparse
import json

def main():
    """ä¸»æ§‹å»ºå‡½æ•¸"""
    parser = argparse.ArgumentParser(description="æ§‹å»º RAG æª¢ç´¢ç´¢å¼•")
    parser.add_argument("--type", type=str, choices=["chroma", "simple", "both"], 
                       default="both", help="ç´¢å¼•é¡å‹")
    parser.add_argument("--data_path", type=str, default="data/raw/pairs.jsonl", 
                       help="åŸå§‹æ•¸æ“šè·¯å¾‘")
    parser.add_argument("--output_dir", type=str, default="data/chroma/social_debate", 
                       help="Chroma ç´¢å¼•è¼¸å‡ºç›®éŒ„")
    parser.add_argument("--simple_output", type=str, default="src/rag/data/rag/simple_index.json",
                       help="ç°¡å–®ç´¢å¼•è¼¸å‡ºè·¯å¾‘")
    parser.add_argument("--max_docs", type=int, default=None, help="æœ€å¤§æ–‡æª”æ•¸ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰")
    parser.add_argument("--batch_size", type=int, default=None, help="æ‰¹æ¬¡å¤§å°")
    args = parser.parse_args()
    
    print("=" * 50)
    print("ğŸš€ RAG ç´¢å¼•æ§‹å»ºç¨‹å¼")
    print("=" * 50)
    
    # è¼‰å…¥é…ç½®
    config = ConfigLoader.load("rag")
    
    # åˆä½µé…ç½®å’Œå‘½ä»¤è¡Œåƒæ•¸
    chroma_config = config.get("chroma", {})
    indexing_config = config.get("indexing", {})
    embedding_config = chroma_config.get("embedding", {})
    
    data_path = args.data_path or indexing_config.get("data_source", "data/raw/pairs.jsonl")
    batch_size = args.batch_size or embedding_config.get("batch_size", 500)
    
    print(f"\né…ç½®åƒæ•¸:")
    print(f"  - ç´¢å¼•é¡å‹: {args.type}")
    print(f"  - æ•¸æ“šè·¯å¾‘: {data_path}")
    print(f"  - æ‰¹æ¬¡å¤§å°: {batch_size}")
    if args.max_docs:
        print(f"  - æœ€å¤§æ–‡æª”æ•¸: {args.max_docs}")
    print("-" * 50)
    
    try:
        # æ§‹å»º Chroma ç´¢å¼•
        if args.type in ["chroma", "both"]:
            print("\nğŸ“š æ§‹å»º Chroma å‘é‡ç´¢å¼•...")
            
            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
            output_dir = Path(args.output_dir)
            output_dir.parent.mkdir(parents=True, exist_ok=True)
            
            # åŸ·è¡Œæ§‹å»º
            stats = build_chroma_index(
                data_path=data_path,
                output_dir=str(output_dir),
                max_docs=args.max_docs,
                batch_size=batch_size
            )
            
            print(f"\nâœ… Chroma ç´¢å¼•æ§‹å»ºå®Œæˆï¼")
            print(f"  - ç¸½æ–‡æª”æ•¸: {stats.get('total_docs', 0)}")
            print(f"  - ç´¢å¼•ä½ç½®: {output_dir}")
        
        # æ§‹å»ºç°¡å–®ç´¢å¼•
        if args.type in ["simple", "both"]:
            print("\nğŸ“„ æ§‹å»ºç°¡å–® JSON ç´¢å¼•...")
            
            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
            simple_output = Path(args.simple_output)
            simple_output.parent.mkdir(parents=True, exist_ok=True)
            
            # åŸ·è¡Œæ§‹å»º
            docs = build_simple_index(
                data_path=data_path,
                output_path=str(simple_output),
                max_docs=args.max_docs  # ä¸è¨­å®šé è¨­å€¼ï¼Œè™•ç†æ‰€æœ‰æ•¸æ“š
            )
            
            print(f"\nâœ… ç°¡å–®ç´¢å¼•æ§‹å»ºå®Œæˆï¼")
            print(f"  - æ–‡æª”æ•¸: {len(docs)}")
            print(f"  - ç´¢å¼•ä½ç½®: {simple_output}")
        
        print("\nğŸ‰ æ‰€æœ‰ç´¢å¼•æ§‹å»ºå®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ æ§‹å»ºå¤±æ•—: {e}")
        raise

def build_demo_index():
    """æ§‹å»ºæ¼”ç¤ºç”¨çš„ç°¡å–®ç´¢å¼•"""
    demo_docs = [
        {
            "id": "doc_001",
            "content": "äººå·¥æ™ºæ…§çš„ç›£ç®¡æ˜¯ä¸€å€‹è¤‡é›œçš„è­°é¡Œã€‚æ”¯æŒè€…èªç‚ºï¼Œé©ç•¶çš„ç›£ç®¡å¯ä»¥é˜²æ­¢ AI è¢«æ¿«ç”¨ï¼Œä¿è­·å…¬æ°‘éš±ç§å’Œå®‰å…¨ã€‚ä¾‹å¦‚ï¼Œæ­ç›Ÿçš„ AI æ³•æ¡ˆå°±æ˜¯ä¸€å€‹å˜—è©¦å»ºç«‹å…¨é¢ç›£ç®¡æ¡†æ¶çš„ä¾‹å­ã€‚",
            "metadata": {
                "type": "expert_opinion",
                "topic": "AIç›£ç®¡",
                "stance": "æ”¯æŒ",
                "quality_score": 0.85
            }
        },
        {
            "id": "doc_002",
            "content": "åå°æ”¿åºœç›£ç®¡ AI çš„è«–é»ä¸»è¦é›†ä¸­åœ¨å‰µæ–°å’Œç«¶çˆ­åŠ›æ–¹é¢ã€‚éåº¦ç›£ç®¡å¯èƒ½æœƒæ‰¼æ®ºå‰µæ–°ï¼Œä½¿ä¼æ¥­é›£ä»¥å¿«é€Ÿè¿­ä»£å’Œæ”¹é€²æŠ€è¡“ã€‚çŸ½è°·çš„è¨±å¤šç§‘æŠ€å…¬å¸éƒ½æ“”å¿ƒåš´æ ¼çš„ç›£ç®¡æœƒé™ä½ä»–å€‘åœ¨å…¨çƒå¸‚å ´çš„ç«¶çˆ­åŠ›ã€‚",
            "metadata": {
                "type": "industry_perspective",
                "topic": "AIç›£ç®¡",
                "stance": "åå°",
                "quality_score": 0.82
            }
        },
        {
            "id": "doc_003",
            "content": "æ ¹æ“šéº»çœç†å·¥å­¸é™¢çš„ç ”ç©¶ï¼Œå¹³è¡¡çš„ AI ç›£ç®¡æ–¹æ³•å¯èƒ½æ˜¯æœ€ä½³é¸æ“‡ã€‚é€™ç¨®æ–¹æ³•æ—¢ä¿è­·å…¬çœ¾åˆ©ç›Šï¼Œåˆä¸æœƒéåº¦é™åˆ¶æŠ€è¡“ç™¼å±•ã€‚ç ”ç©¶å»ºè­°æ¡ç”¨é¢¨éšªå°å‘çš„ç›£ç®¡æ¡†æ¶ï¼Œå°é«˜é¢¨éšªæ‡‰ç”¨å¯¦æ–½æ›´åš´æ ¼çš„æ§åˆ¶ã€‚",
            "metadata": {
                "type": "research",
                "topic": "AIç›£ç®¡",
                "stance": "ä¸­ç«‹",
                "quality_score": 0.90
            }
        }
    ]
    
    # ä¿å­˜æ¼”ç¤ºç´¢å¼•
    demo_path = Path("src/rag/data/rag/simple_index.json")
    demo_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(demo_path, 'w', encoding='utf-8') as f:
        json.dump({
            "documents": demo_docs,
            "metadata": {
                "version": "1.0",
                "created_at": "2024-01-01",
                "total_documents": len(demo_docs)
            }
        }, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æ¼”ç¤ºç´¢å¼•å·²ä¿å­˜åˆ°: {demo_path}")

if __name__ == "__main__":
    # å¦‚æœæ²’æœ‰åŸå§‹æ•¸æ“šï¼Œå…ˆå»ºç«‹æ¼”ç¤ºç´¢å¼•
    if not Path("data/raw/pairs.jsonl").exists():
        print("âš ï¸ æ‰¾ä¸åˆ°åŸå§‹æ•¸æ“šï¼Œå»ºç«‹æ¼”ç¤ºç´¢å¼•...")
        build_demo_index()
    else:
        main() 
"""
å¹³è¡Œè™•ç†è¾¯è«–å”èª¿å™¨
æ”¯æ´ RL + GNN + RAG å¹³è¡Œé‹è¡Œï¼Œå‹•æ…‹èªªæœ/åé§æ©Ÿåˆ¶
"""

import asyncio
import concurrent.futures
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
import json
import time
from pathlib import Path

try:
    from ..rl.policy_network import select_strategy, choose_snippet, PolicyNetwork
    from ..gnn.social_encoder import social_vec
    from ..rag.retriever import create_enhanced_retriever
    from ..gpt_interface.gpt_client import chat
except ImportError:
    # å›é€€å°å…¥
    import sys
    sys.path.append(str(Path(__file__).parent.parent))
    from rl.policy_network import select_strategy, choose_snippet, PolicyNetwork
    from gnn.social_encoder import social_vec
    from rag.retriever import create_enhanced_retriever
    from gpt_interface.gpt_client import chat

@dataclass
class AgentState:
    """Agent ç‹€æ…‹"""
    agent_id: str
    current_stance: float  # -1.0 åˆ° 1.0ï¼Œç«‹å ´å¼·åº¦
    conviction: float      # 0.0 åˆ° 1.0ï¼Œä¿¡å¿µå …å®šåº¦
    social_context: List[float]  # ç¤¾æœƒèƒŒæ™¯å‘é‡
    persuasion_history: List[float]  # è¢«èªªæœæ­·å²
    attack_history: List[float]     # æ”»æ“Šæ­·å²
    
    def update_stance(self, persuasion_score: float, attack_score: float):
        """æ›´æ–°ç«‹å ´å’Œä¿¡å¿µ"""
        # è¨ˆç®—èªªæœæ•ˆæœ
        persuasion_effect = persuasion_score * (1.0 - self.conviction)
        
        # è¨ˆç®—æ”»æ“ŠæŠµæŠ—
        attack_resistance = self.conviction * 0.8
        attack_effect = max(0, attack_score - attack_resistance)
        
        # æ›´æ–°ç«‹å ´ (èªªæœä½¿ç«‹å ´è¶¨å‘ä¸­æ€§ï¼Œæ”»æ“Šä½¿ç«‹å ´æ¥µåŒ–)
        if persuasion_score > 0.6:  # è¢«èªªæœ
            self.current_stance *= (1.0 - persuasion_effect * 0.3)
            self.conviction *= 0.9  # ä¿¡å¿µæ¸›å¼±
        
        if attack_effect > 0.3:  # è¢«æ”»æ“Š
            self.current_stance *= (1.0 + attack_effect * 0.2)  # ç«‹å ´æ›´æ¥µç«¯
            self.conviction = min(1.0, self.conviction * 1.1)  # ä¿¡å¿µå¢å¼·
        
        # è¨˜éŒ„æ­·å²
        self.persuasion_history.append(persuasion_score)
        self.attack_history.append(attack_score)
        
        # ä¿æŒæ­·å²é•·åº¦
        if len(self.persuasion_history) > 10:
            self.persuasion_history.pop(0)
        if len(self.attack_history) > 10:
            self.attack_history.pop(0)

@dataclass
class DebateRound:
    """è¾¯è«–å›åˆ"""
    round_number: int
    topic: str
    agent_states: Dict[str, AgentState]
    history: List[Dict]
    
class ParallelOrchestrator:
    """å¹³è¡Œè™•ç†è¾¯è«–å”èª¿å™¨"""
    
    def __init__(self):
        self.policy_network = PolicyNetwork()
        self.retriever = create_enhanced_retriever()
        self.agent_states = {}
        self.debate_history = []
        
        # åŸ·è¡Œå™¨æ± 
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=4)
        
        print("âœ… å¹³è¡Œè¾¯è«–å”èª¿å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def initialize_agents(self, agent_configs: List[Dict]) -> Dict[str, AgentState]:
        """åˆå§‹åŒ– Agent ç‹€æ…‹"""
        agents = {}
        
        for config in agent_configs:
            agent_id = config['id']
            agents[agent_id] = AgentState(
                agent_id=agent_id,
                current_stance=config.get('initial_stance', 0.0),
                conviction=config.get('initial_conviction', 0.7),
                social_context=config.get('social_context', [0.0] * 128),
                persuasion_history=[],
                attack_history=[]
            )
        
        self.agent_states = agents
        print(f"âœ… åˆå§‹åŒ– {len(agents)} å€‹ Agent")
        return agents
    
    async def parallel_analysis(self, agent_id: str, topic: str, 
                              history: List[str]) -> Dict:
        """å¹³è¡ŒåŸ·è¡Œ RL + GNN + RAG åˆ†æ"""
        
        # æ§‹å»ºæŸ¥è©¢ä¸Šä¸‹æ–‡
        recent_turns = history[-3:] if history else []
        context = f"Topic: {topic}\nRecent: {' '.join(recent_turns)}"
        agent_state = self.agent_states[agent_id]
        
        # å‰µå»ºç•°æ­¥ä»»å‹™
        loop = asyncio.get_event_loop()
        
        # 1. RL ç­–ç•¥é¸æ“‡
        rl_task = loop.run_in_executor(
            self.executor,
            self._rl_analysis,
            context, agent_state.social_context
        )
        
        # 2. GNN ç¤¾æœƒåˆ†æ
        gnn_task = loop.run_in_executor(
            self.executor,
            self._gnn_analysis,
            agent_id, agent_state
        )
        
        # 3. RAG è­‰æ“šæª¢ç´¢
        rag_task = loop.run_in_executor(
            self.executor,
            self._rag_analysis,
            context, topic
        )
        
        # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
        try:
            rl_result, gnn_result, rag_result = await asyncio.gather(
                rl_task, gnn_task, rag_task
            )
            
            return {
                'rl': rl_result,
                'gnn': gnn_result,
                'rag': rag_result,
                'timestamp': time.time()
            }
        except Exception as e:
            print(f"âŒ å¹³è¡Œåˆ†æå¤±æ•—: {e}")
            return self._fallback_analysis(context, agent_id)
    
    def _rl_analysis(self, context: str, social_context: List[float]) -> Dict:
        """RL ç­–ç•¥åˆ†æ"""
        try:
            strategy = select_strategy(context, "", social_context)
            
            # é æ¸¬å“è³ªåˆ†æ•¸
            quality_score = self.policy_network.predict_quality(context)
            
            return {
                'strategy': strategy,
                'quality_score': quality_score,
                'confidence': 0.8  # å¯ä»¥å¾æ¨¡å‹ç²å–
            }
        except Exception as e:
            print(f"âš ï¸ RL åˆ†æå¤±æ•—: {e}")
            return {'strategy': 'analytical', 'quality_score': 0.5, 'confidence': 0.3}
    
    def _gnn_analysis(self, agent_id: str, agent_state: AgentState) -> Dict:
        """GNN ç¤¾æœƒé—œä¿‚åˆ†æ"""
        try:
            # ç²å–ç¤¾æœƒå‘é‡
            social_vector = social_vec(agent_id)
            
            # åˆ†æç¤¾æœƒå½±éŸ¿åŠ›
            influence_score = sum(social_vector[:10]) / 10  # ç°¡åŒ–è¨ˆç®—
            
            # åˆ†æç«‹å ´è®ŠåŒ–è¶¨å‹¢
            stance_trend = 0.0
            if len(agent_state.persuasion_history) >= 2:
                recent_persuasion = sum(agent_state.persuasion_history[-3:]) / 3
                stance_trend = recent_persuasion - 0.5
            
            return {
                'social_vector': social_vector,
                'influence_score': influence_score,
                'stance_trend': stance_trend,
                'current_stance': agent_state.current_stance,
                'conviction': agent_state.conviction
            }
        except Exception as e:
            print(f"âš ï¸ GNN åˆ†æå¤±æ•—: {e}")
            return {
                'social_vector': [0.0] * 128,
                'influence_score': 0.5,
                'stance_trend': 0.0,
                'current_stance': agent_state.current_stance,
                'conviction': agent_state.conviction
            }
    
    def _rag_analysis(self, context: str, topic: str) -> Dict:
        """RAG è­‰æ“šæª¢ç´¢åˆ†æ"""
        try:
            # æª¢ç´¢è­‰æ“šæ± 
            evidence_pool = self.retriever.retrieve(
                query=context,
                k=8,
                index_type='high_quality'
            )
            
            # é¸æ“‡æœ€ä½³è­‰æ“š
            best_evidence = choose_snippet(context, evidence_pool)
            
            # åˆ†æè­‰æ“šé¡å‹åˆ†å¸ƒ
            evidence_types = {}
            for ev in evidence_pool:
                ev_type = ev.get('type', 'unknown')
                evidence_types[ev_type] = evidence_types.get(ev_type, 0) + 1
            
            return {
                'evidence_pool': evidence_pool,
                'best_evidence': best_evidence,
                'evidence_types': evidence_types,
                'total_evidence': len(evidence_pool)
            }
        except Exception as e:
            print(f"âš ï¸ RAG åˆ†æå¤±æ•—: {e}")
            return {
                'evidence_pool': [],
                'best_evidence': "No evidence available",
                'evidence_types': {},
                'total_evidence': 0
            }
    
    def _fallback_analysis(self, context: str, agent_id: str) -> Dict:
        """å›é€€åˆ†æ"""
        return {
            'rl': {'strategy': 'analytical', 'quality_score': 0.5, 'confidence': 0.3},
            'gnn': {'social_vector': [0.0] * 128, 'influence_score': 0.5, 
                   'stance_trend': 0.0, 'current_stance': 0.0, 'conviction': 0.7},
            'rag': {'evidence_pool': [], 'best_evidence': "No evidence available",
                   'evidence_types': {}, 'total_evidence': 0},
            'timestamp': time.time()
        }
    
    def fuse_analysis_results(self, analysis_results: Dict, agent_id: str) -> Dict:
        """èåˆåˆ†æçµæœ"""
        rl_result = analysis_results['rl']
        gnn_result = analysis_results['gnn']
        rag_result = analysis_results['rag']
        
        # ç­–ç•¥èª¿æ•´ï¼šæ ¹æ“šç¤¾æœƒå½±éŸ¿åŠ›å’Œç«‹å ´èª¿æ•´ç­–ç•¥
        base_strategy = rl_result['strategy']
        influence_score = gnn_result['influence_score']
        current_stance = gnn_result['current_stance']
        
        # é«˜å½±éŸ¿åŠ› + å¼·ç«‹å ´ = æ›´ç©æ¥µ
        if influence_score > 0.6 and abs(current_stance) > 0.5:
            if base_strategy == 'analytical':
                adjusted_strategy = 'aggressive'
            else:
                adjusted_strategy = base_strategy
        # ä½å½±éŸ¿åŠ› + å¼±ç«‹å ´ = æ›´è¬¹æ…
        elif influence_score < 0.4 and abs(current_stance) < 0.3:
            if base_strategy == 'aggressive':
                adjusted_strategy = 'defensive'
            else:
                adjusted_strategy = base_strategy
        else:
            adjusted_strategy = base_strategy
        
        # è­‰æ“šé¸æ“‡ï¼šæ ¹æ“šç­–ç•¥èª¿æ•´è­‰æ“šé¸æ“‡
        evidence = rag_result['best_evidence']
        evidence_confidence = min(1.0, rag_result['total_evidence'] / 5.0)
        
        return {
            'final_strategy': adjusted_strategy,
            'evidence': evidence,
            'evidence_confidence': evidence_confidence,
            'social_influence': influence_score,
            'stance_strength': abs(current_stance),
            'conviction': gnn_result['conviction'],
            'fusion_timestamp': time.time()
        }
    
    async def generate_response(self, agent_id: str, topic: str, 
                              history: List[str], target_agents: List[str]) -> str:
        """ç”Ÿæˆè¾¯è«–å›è¦†"""
        
        # 1. å¹³è¡Œåˆ†æ
        print(f"ğŸ”„ Agent {agent_id} é–‹å§‹å¹³è¡Œåˆ†æ...")
        analysis_start = time.time()
        
        analysis_results = await self.parallel_analysis(agent_id, topic, history)
        
        analysis_time = time.time() - analysis_start
        print(f"âš¡ å¹³è¡Œåˆ†æå®Œæˆ ({analysis_time:.2f}s)")
        
        # 2. èåˆçµæœ
        fused_results = self.fuse_analysis_results(analysis_results, agent_id)
        
        # 3. æ§‹å»ºæç¤º
        agent_state = self.agent_states[agent_id]
        recent_history = history[-4:] if history else []
        
        # åˆ†æç›®æ¨™ Agent çš„å¼±é»
        target_analysis = self._analyze_targets(target_agents, history)
        
        prompt = self._build_enhanced_prompt(
            agent_id, topic, recent_history, fused_results, target_analysis
        )
        
        # 4. ç”Ÿæˆå›è¦†
        print(f"ğŸ¤– Agent {agent_id} ä½¿ç”¨ {fused_results['final_strategy']} ç­–ç•¥ç”Ÿæˆå›è¦†...")
        response = chat(prompt)
        
        # 5. è©•ä¼°å›è¦†æ•ˆæœ
        response_effects = self._evaluate_response(response, target_agents)
        
        return response
    
    def _analyze_targets(self, target_agents: List[str], history: List[str]) -> Dict:
        """åˆ†æç›®æ¨™ Agent çš„å¼±é»å’Œæ©Ÿæœƒ"""
        target_analysis = {}
        
        for target_id in target_agents:
            if target_id in self.agent_states:
                target_state = self.agent_states[target_id]
                
                # åˆ†æèªªæœæ©Ÿæœƒ
                persuasion_opportunity = 1.0 - target_state.conviction
                
                # åˆ†ææ”»æ“Šæ©Ÿæœƒ
                attack_opportunity = abs(target_state.current_stance)
                
                # åˆ†ææ­·å²è¶¨å‹¢
                recent_persuasion = 0.0
                if target_state.persuasion_history:
                    recent_persuasion = sum(target_state.persuasion_history[-2:]) / 2
                
                target_analysis[target_id] = {
                    'persuasion_opportunity': persuasion_opportunity,
                    'attack_opportunity': attack_opportunity,
                    'recent_persuasion': recent_persuasion,
                    'stance': target_state.current_stance,
                    'conviction': target_state.conviction
                }
        
        return target_analysis
    
    def _build_enhanced_prompt(self, agent_id: str, topic: str, history: List[str],
                              fused_results: Dict, target_analysis: Dict) -> str:
        """æ§‹å»ºå¢å¼·æç¤º"""
        
        agent_state = self.agent_states[agent_id]
        strategy = fused_results['final_strategy']
        evidence = fused_results['evidence']
        
        # æ­·å²å°è©±
        history_text = '\n'.join(f"Turn {i+1}: {turn}" for i, turn in enumerate(history))
        
        # ç›®æ¨™åˆ†æ
        target_info = ""
        for target_id, analysis in target_analysis.items():
            target_info += f"\n- {target_id}: ç«‹å ´{analysis['stance']:.2f}, ä¿¡å¿µ{analysis['conviction']:.2f}, èªªæœæ©Ÿæœƒ{analysis['persuasion_opportunity']:.2f}"
        
        # ç­–ç•¥æŒ‡å°
        strategy_guidance = {
            'aggressive': "æ¡ç”¨å¼·å‹¢æ”»æ“Šï¼ŒæŒ‡å‡ºå°æ–¹è«–é»çš„æ¼æ´å’ŒçŸ›ç›¾",
            'defensive': "é˜²ç¦¦æ€§å›æ‡‰ï¼Œä¿è­·è‡ªå·±çš„ç«‹å ´ä¸¦åé§æ”»æ“Š",
            'analytical': "ç†æ€§åˆ†æï¼Œä½¿ç”¨é‚è¼¯å’Œè­‰æ“šé€²è¡Œè«–è­‰",
            'empathetic': "åŒç†å¿ƒèªªæœï¼Œå°‹æ‰¾å…±åŒé»ä¸¦æº«å’Œåœ°æ”¹è®Šå°æ–¹è§€é»"
        }
        
        return f"""ä½ æ˜¯è¾¯è«– Agent {agent_id}ï¼Œåƒèˆ‡é—œæ–¼ "{topic}" çš„è¾¯è«–ã€‚

ç•¶å‰ç‹€æ…‹ï¼š
- ä½ çš„ç«‹å ´å¼·åº¦ï¼š{agent_state.current_stance:.2f} (-1åˆ°1)
- ä½ çš„ä¿¡å¿µå …å®šåº¦ï¼š{agent_state.conviction:.2f} (0åˆ°1)
- é¸å®šç­–ç•¥ï¼š{strategy}

å°è©±æ­·å²ï¼š
{history_text}

è­‰æ“šæ”¯æŒï¼š
{evidence}

ç›®æ¨™å°æ‰‹åˆ†æï¼š{target_info}

ç­–ç•¥æŒ‡å°ï¼š{strategy_guidance.get(strategy, '')}

è«‹ç”Ÿæˆä½ çš„ä¸‹ä¸€è¼ªç™¼è¨€ï¼ˆâ‰¤150å­—ï¼‰ï¼š
1. æ ¹æ“š {strategy} ç­–ç•¥è¡Œå‹•
2. åˆ©ç”¨æä¾›çš„è­‰æ“šæ”¯æŒä½ çš„è«–é»
3. é‡å°å°æ‰‹çš„å¼±é»é€²è¡Œæ”»æ“Šæˆ–èªªæœ
4. å¼•ç”¨è­‰æ“šæ™‚ä½¿ç”¨ [CITE] æ¨™è¨˜
5. ä¿æŒä½ çš„ç«‹å ´ä½†å…è¨±é©åº¦èª¿æ•´

ç™¼è¨€ï¼š"""
    
    def _evaluate_response(self, response: str, target_agents: List[str]) -> Dict:
        """è©•ä¼°å›è¦†çš„èªªæœåŠ›å’Œæ”»æ“Šæ€§"""
        
        # ç°¡å–®çš„å•Ÿç™¼å¼è©•ä¼°
        persuasion_indicators = ['however', 'consider', 'understand', 'perspective', 'common']
        attack_indicators = ['wrong', 'flawed', 'mistake', 'ignore', 'fail']
        evidence_indicators = ['[CITE]', 'study', 'research', 'data', 'evidence']
        
        persuasion_score = sum(1 for indicator in persuasion_indicators if indicator in response.lower()) / len(persuasion_indicators)
        attack_score = sum(1 for indicator in attack_indicators if indicator in response.lower()) / len(attack_indicators)
        evidence_score = sum(1 for indicator in evidence_indicators if indicator in response.lower()) / len(evidence_indicators)
        
        return {
            'persuasion_score': min(1.0, persuasion_score),
            'attack_score': min(1.0, attack_score),
            'evidence_score': min(1.0, evidence_score),
            'length_score': min(1.0, len(response.split()) / 100)
        }
    
    async def run_debate_round(self, round_number: int, topic: str, 
                             agent_order: List[str]) -> DebateRound:
        """åŸ·è¡Œä¸€è¼ªè¾¯è«–"""
        
        print(f"\nğŸ­ é–‹å§‹ç¬¬ {round_number} è¼ªè¾¯è«–")
        print(f"ä¸»é¡Œ: {topic}")
        print(f"ç™¼è¨€é †åº: {' â†’ '.join(agent_order)}")
        
        round_responses = []
        
        for i, agent_id in enumerate(agent_order):
            print(f"\n--- Agent {agent_id} ç™¼è¨€ ---")
            
            # ç¢ºå®šç›®æ¨™å°æ‰‹
            other_agents = [aid for aid in agent_order if aid != agent_id]
            
            # ç”Ÿæˆå›è¦†
            response = await self.generate_response(
                agent_id, topic, 
                [r['content'] for r in round_responses], 
                other_agents
            )
            
            # è©•ä¼°æ•ˆæœ
            effects = self._evaluate_response(response, other_agents)
            
            # è¨˜éŒ„å›è¦†
            round_responses.append({
                'agent_id': agent_id,
                'content': response,
                'effects': effects,
                'timestamp': time.time()
            })
            
            print(f"Agent {agent_id}: {response[:100]}...")
            print(f"æ•ˆæœè©•ä¼°: èªªæœ{effects['persuasion_score']:.2f}, æ”»æ“Š{effects['attack_score']:.2f}")
            
            # æ›´æ–°å…¶ä»– Agent çš„ç‹€æ…‹
            for target_id in other_agents:
                if target_id in self.agent_states:
                    self.agent_states[target_id].update_stance(
                        effects['persuasion_score'],
                        effects['attack_score']
                    )
        
        # å‰µå»ºå›åˆè¨˜éŒ„
        debate_round = DebateRound(
            round_number=round_number,
            topic=topic,
            agent_states=dict(self.agent_states),
            history=round_responses
        )
        
        self.debate_history.append(debate_round)
        
        # é¡¯ç¤ºå›åˆçµæœ
        self._display_round_summary(debate_round)
        
        return debate_round
    
    def _display_round_summary(self, debate_round: DebateRound):
        """é¡¯ç¤ºå›åˆç¸½çµ"""
        print(f"\nğŸ“Š ç¬¬ {debate_round.round_number} è¼ªç¸½çµ")
        print("=" * 50)
        
        for agent_id, state in debate_round.agent_states.items():
            print(f"Agent {agent_id}:")
            print(f"  ç«‹å ´: {state.current_stance:+.2f} | ä¿¡å¿µ: {state.conviction:.2f}")
            if state.persuasion_history:
                avg_persuasion = sum(state.persuasion_history[-3:]) / min(3, len(state.persuasion_history))
                print(f"  è¿‘æœŸè¢«èªªæœåº¦: {avg_persuasion:.2f}")
    
    def get_debate_summary(self) -> Dict:
        """ç²å–è¾¯è«–ç¸½çµ"""
        if not self.debate_history:
            return {"message": "å°šæœªé–‹å§‹è¾¯è«–"}
        
        # åˆ†æç«‹å ´è®ŠåŒ–
        stance_changes = {}
        for agent_id in self.agent_states:
            initial_stance = 0.0  # å‡è¨­åˆå§‹ç«‹å ´ç‚ºä¸­æ€§
            current_stance = self.agent_states[agent_id].current_stance
            stance_changes[agent_id] = current_stance - initial_stance
        
        # æ‰¾å‡ºæœ€æœ‰èªªæœåŠ›çš„ Agent
        most_persuasive = max(stance_changes.keys(), 
                            key=lambda x: abs(stance_changes[x]))
        
        return {
            "total_rounds": len(self.debate_history),
            "stance_changes": stance_changes,
            "most_persuasive_agent": most_persuasive,
            "final_states": {aid: {
                "stance": state.current_stance,
                "conviction": state.conviction
            } for aid, state in self.agent_states.items()}
        }

# ä¾¿åˆ©å‡½æ•¸
def create_parallel_orchestrator():
    """å‰µå»ºå¹³è¡Œå”èª¿å™¨"""
    return ParallelOrchestrator() 
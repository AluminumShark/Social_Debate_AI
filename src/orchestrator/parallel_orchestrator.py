"""
å¹³è¡Œè¾¯è«–å”èª¿å™¨
æ•´åˆ RLã€GNNã€RAG ä¸‰å€‹æ¨¡çµ„çš„å¹³è¡Œè™•ç†
"""

import asyncio
from concurrent.futures import ThreadPoolExecutor
import time
from dataclasses import dataclass
from typing import Dict, List, Any, Optional
from pathlib import Path
import sys
import random
import numpy as np

# å»¶é²å°å…¥ï¼Œé¿å…å¾ªç’°ä¾è³´
# PolicyNetwork å’Œ Retriever å°‡åœ¨éœ€è¦æ™‚å‹•æ…‹å°å…¥

# å°å…¥ GPT æ¥å£
try:
    from gpt_interface.gpt_client import chat
except ImportError:
    # å®šç¾©è™›æ“¬å‡½æ•¸ï¼Œä»¥é˜² GPT ä¸å¯ç”¨
    def chat(prompt: str) -> str:
        """è™›æ“¬ chat å‡½æ•¸"""
        # é€™è£¡æ‡‰è©²èª¿ç”¨å¯¦éš›çš„ GPT æ¥å£
        # ç‚ºäº†æ¼”ç¤ºï¼Œè¿”å›ä¸€å€‹æ¨¡æ“¬å›æ‡‰
        responses = [
            "åŸºæ–¼æ·±å…¥åˆ†æï¼Œæˆ‘èªç‚ºé€™å€‹è­°é¡Œéœ€è¦å¾å¤šå€‹è§’åº¦ä¾†è€ƒæ…®ã€‚é¦–å…ˆï¼Œæˆ‘å€‘å¿…é ˆæ‰¿èªå…¶è¤‡é›œæ€§ï¼Œä¸¦ç†è§£ä¸åŒç«‹å ´èƒŒå¾Œçš„åˆç†é—œåˆ‡ã€‚",
            "è®“æˆ‘å¾å¦ä¸€å€‹è§’åº¦ä¾†é—¡è¿°é€™å€‹å•é¡Œã€‚é›–ç„¶å°æ–¹æå‡ºäº†ä¸€äº›è§€é»ï¼Œä½†æˆ‘èªç‚ºä»–å€‘å¿½ç•¥äº†å¹¾å€‹é—œéµå› ç´ ã€‚",
            "æˆ‘ç†è§£å°æ–¹çš„æ“”æ†‚ï¼Œä½†æˆ‘å€‘éœ€è¦åŸºæ–¼äº‹å¯¦å’Œæ•¸æ“šä¾†è¨è«–ã€‚æ ¹æ“šæœ€æ–°çš„ç ”ç©¶é¡¯ç¤ºï¼Œé€™å€‹è­°é¡Œçš„å½±éŸ¿é æ¯”è¡¨é¢çœ‹èµ·ä¾†æ›´æ·±é ã€‚"
        ]
        return random.choice(responses)

# å˜—è©¦å°å…¥æ‰€éœ€æ¨¡çµ„
try:
    from rl.policy_network import select_strategy as _select_strategy, choose_snippet as _choose_snippet, PolicyNetwork as _PolicyNetwork
    from gnn.social_encoder import social_vec as _social_vec, get_social_influence_score, predict_persuasion
    from rag.retriever import create_enhanced_retriever as _create_enhanced_retriever
    from utils.config_loader import ConfigLoader as _ConfigLoader
    
    # å‰µå»ºåŒ…è£å‡½æ•¸
    def select_strategy(query: str, context: str = "", social_context: List[float] = None) -> str:
        """åŒ…è£ select_strategy å‡½æ•¸"""
        return _select_strategy(query, context, social_context)
    
    def choose_snippet(state_text: str, pool: List[Dict]) -> str:
        """åŒ…è£ choose_snippet å‡½æ•¸"""
        return _choose_snippet(state_text, pool)
    
    def social_vec(agent_id: str) -> List[float]:
        """åŒ…è£ social_vec å‡½æ•¸"""
        return _social_vec(agent_id)
        
except ImportError as e:
    print(f"âš ï¸ éƒ¨åˆ†æ¨¡çµ„å°å…¥å¤±æ•—: {e}")
    print("âš ï¸ ä½¿ç”¨è™›æ“¬å‡½æ•¸é‹è¡Œ")
    
    # å®šç¾©è™›æ“¬å‡½æ•¸
    def select_strategy(query: str, context: str = "", social_context: List[float] = None) -> str:
        """è™›æ“¬ select_strategy å‡½æ•¸"""
        strategies = ['analytical', 'aggressive', 'defensive', 'empathetic']
        return random.choice(strategies)
    
    def choose_snippet(state_text: str, pool: List[Dict]) -> str:
        """è™›æ“¬ choose_snippet å‡½æ•¸"""
        if pool:
            return pool[0].get('content', 'No evidence available')
        return "No evidence available"
    
    def social_vec(agent_id: str) -> List[float]:
        """è™›æ“¬ social_vec å‡½æ•¸"""
        return [random.random() for _ in range(128)]

@dataclass
class AgentState:
    """Agent ç‹€æ…‹"""
    agent_id: str
    current_stance: float  # -1.0 åˆ° 1.0ï¼Œç«‹å ´å¼·åº¦
    conviction: float      # 0.0 åˆ° 1.0ï¼Œä¿¡å¿µå …å®šåº¦
    social_context: List[float]  # ç¤¾æœƒèƒŒæ™¯å‘é‡
    persuasion_history: List[float]  # è¢«èªªæœæ­·å²
    attack_history: List[float]     # æ”»æ“Šæ­·å²
    has_surrendered: bool = False  # æ˜¯å¦å·²æŠ•é™
    
    def update_stance(self, persuasion_score: float, attack_score: float):
        """æ›´æ–°ç«‹å ´å’Œä¿¡å¿µ"""
        # è¨ˆç®—èªªæœæ•ˆæœ
        persuasion_effect = persuasion_score * (1.0 - self.conviction)
        
        # è¨ˆç®—æ”»æ“ŠæŠµæŠ—
        attack_resistance = self.conviction * 0.8
        attack_effect = max(0, attack_score - attack_resistance)
        
        # æ›´æ–°ç«‹å ´ (èªªæœä½¿ç«‹å ´è¶¨å‘ä¸­æ€§ï¼Œæ”»æ“Šä½¿ç«‹å ´æ¥µåŒ–)
        if persuasion_score > 0.6:  # è¢«èªªæœ
            self.current_stance *= (1.0 - persuasion_effect * 0.3)
            self.conviction *= 0.85  # ä¿¡å¿µæ¸›å¼±æ›´å¤š
        
        if attack_effect > 0.3:  # è¢«æ”»æ“Š
            self.current_stance *= (1.0 + attack_effect * 0.2)  # ç«‹å ´æ›´æ¥µç«¯
            self.conviction = min(1.0, self.conviction * 1.1)  # ä¿¡å¿µå¢å¼·
        
        # è¨˜éŒ„æ­·å²
        self.persuasion_history.append(persuasion_score)
        self.attack_history.append(attack_score)
        
        # ä¿æŒæ­·å²é•·åº¦
        if len(self.persuasion_history) > 10:
            self.persuasion_history.pop(0)
        if len(self.attack_history) > 10:
            self.attack_history.pop(0)
        
        # æª¢æŸ¥æ˜¯å¦æ‡‰è©²æŠ•é™ï¼ˆæ¢ä»¶æ”¾å¯¬ï¼‰
        if len(self.persuasion_history) >= 2:
            recent_persuasion = sum(self.persuasion_history[-2:]) / 2
            # æ¢ä»¶1ï¼šé«˜èªªæœåº¦ + ä½ä¿¡å¿µ
            if recent_persuasion > 0.6 and self.conviction < 0.4:
                self.has_surrendered = True
                print(f"ğŸ’” {self.agent_id} è¢«èªªæœäº†ï¼Œé¸æ“‡æŠ•é™ï¼")
            # æ¢ä»¶2ï¼šç«‹å ´å·²ç¶“æ¥è¿‘ä¸­ç«‹
            elif abs(self.current_stance) < 0.2 and self.conviction < 0.5:
                self.has_surrendered = True
                print(f"ğŸ’” {self.agent_id} ç«‹å ´å‹•æ–ï¼Œé¸æ“‡æŠ•é™ï¼")
            # æ¢ä»¶3ï¼šé€£çºŒè¢«é«˜åº¦èªªæœ
            elif len(self.persuasion_history) >= 3:
                consecutive_high = all(score > 0.5 for score in self.persuasion_history[-3:])
                if consecutive_high:
                    self.has_surrendered = True
                    print(f"ğŸ’” {self.agent_id} é€£çºŒè¢«èªªæœï¼Œé¸æ“‡æŠ•é™ï¼")

@dataclass
class DebateRound:
    """è¾¯è«–å›åˆ"""
    round_number: int
    topic: str
    agent_states: Dict[str, AgentState]
    history: List[Dict]
    
class ParallelOrchestrator:
    """å¹³è¡Œè™•ç†è¾¯è«–å”èª¿å™¨"""
    
    def __init__(self):
        self.policy_network = None  # å»¶é²è¼‰å…¥
        self.retriever = None  # å»¶é²è¼‰å…¥
        self.agent_states = {}
        self.debate_history = []
        
        # åŸ·è¡Œå™¨æ± 
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        print("   âœ… å¹³è¡Œè¾¯è«–å”èª¿å™¨åˆå§‹åŒ–å®Œæˆ")
        print("   âš¡ åŸ·è¡Œå™¨æ± : 4 å€‹å·¥ä½œåŸ·è¡Œç·’")
        print("   ğŸ’¾ æ¨¡å‹å»¶é²è¼‰å…¥: å°‡åœ¨é¦–æ¬¡ä½¿ç”¨æ™‚è¼‰å…¥")
    
    def _get_policy_network(self):
        """å»¶é²è¼‰å…¥ PolicyNetwork"""
        if self.policy_network is None:
            print("ğŸ“¦ é¦–æ¬¡ä½¿ç”¨ï¼Œæ­£åœ¨è¼‰å…¥ RL ç­–ç•¥ç¶²è·¯...")
            print("   ğŸ” è¼‰å…¥ DistilBERT æ¨¡å‹...")
            start_time = time.time()
            from rl.policy_network import PolicyNetwork
            self.policy_network = PolicyNetwork()
            load_time = time.time() - start_time
            print(f"   âœ… RL ç­–ç•¥ç¶²è·¯è¼‰å…¥å®Œæˆ ({load_time:.2f}s)")
            print(f"   ğŸ“Š æ¨¡å‹å¤§å°: ~66M åƒæ•¸")
        return self.policy_network
    
    def _get_retriever(self):
        """å»¶é²è¼‰å…¥ Retriever"""
        if self.retriever is None:
            print("ğŸ“¦ é¦–æ¬¡ä½¿ç”¨ï¼Œæ­£åœ¨è¼‰å…¥ RAG æª¢ç´¢å™¨...")
            start_time = time.time()
            try:
                print("   ğŸ” æª¢æŸ¥ Chroma å‘é‡è³‡æ–™åº«...")
                from rag.retriever import create_enhanced_retriever
                self.retriever = create_enhanced_retriever()
                load_time = time.time() - start_time
                print(f"   âœ… RAG æª¢ç´¢å™¨è¼‰å…¥å®Œæˆ ({load_time:.2f}s)")
            except Exception as e:
                print(f"   âš ï¸ å¢å¼·æª¢ç´¢å™¨è¼‰å…¥å¤±æ•—: {e}")
                print("   ğŸ”„ ä½¿ç”¨ç°¡å–®æª¢ç´¢å™¨...")
                from rag.simple_retriever import SimpleRetriever
                self.retriever = SimpleRetriever()
                load_time = time.time() - start_time
                print(f"   âœ… ç°¡å–®æª¢ç´¢å™¨è¼‰å…¥å®Œæˆ ({load_time:.2f}s)")
                # ç²å–çµ±è¨ˆä¿¡æ¯
                stats = self.retriever.get_stats()
                print(f"   ğŸ“Š ç´¢å¼•å¤§å°: {stats.get('total_documents', 0):,} å€‹æ–‡æª”")
        return self.retriever
    
    def initialize_agents(self, agent_configs: List[Dict]) -> Dict[str, AgentState]:
        """åˆå§‹åŒ– Agent ç‹€æ…‹"""
        agents = {}
        
        for config in agent_configs:
            agent_id = config['id']
            agents[agent_id] = AgentState(
                agent_id=agent_id,
                current_stance=config.get('initial_stance', 0.0),
                conviction=config.get('initial_conviction', 0.7),
                social_context=config.get('social_context', [0.0] * 128),
                persuasion_history=[],
                attack_history=[]
            )
        
        self.agent_states = agents
        print(f"âœ… åˆå§‹åŒ– {len(agents)} å€‹ Agent")
        return agents
    
    async def parallel_analysis(self, agent_id: str, topic: str, 
                              history: List[str]) -> Dict:
        """å¹³è¡ŒåŸ·è¡Œ RL + GNN + RAG åˆ†æ"""
        
        # æ§‹å»ºæŸ¥è©¢ä¸Šä¸‹æ–‡
        recent_turns = history[-3:] if history else []
        context = f"Topic: {topic}\nRecent: {' '.join(recent_turns)}"
        agent_state = self.agent_states[agent_id]
        
        # å‰µå»ºç•°æ­¥ä»»å‹™
        loop = asyncio.get_event_loop()
        
        # 1. RL ç­–ç•¥é¸æ“‡
        rl_task = loop.run_in_executor(
            self.executor,
            self._rl_analysis,
            context, agent_state.social_context
        )
        
        # 2. GNN ç¤¾æœƒåˆ†æ
        gnn_task = loop.run_in_executor(
            self.executor,
            self._gnn_analysis,
            agent_id, agent_state
        )
        
        # 3. RAG è­‰æ“šæª¢ç´¢
        rag_task = loop.run_in_executor(
            self.executor,
            self._rag_analysis,
            context, topic
        )
        
        # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
        try:
            rl_result, gnn_result, rag_result = await asyncio.gather(
                rl_task, gnn_task, rag_task
            )
            
            return {
                'rl': rl_result,
                'gnn': gnn_result,
                'rag': rag_result,
                'timestamp': time.time()
            }
        except Exception as e:
            print(f"âŒ å¹³è¡Œåˆ†æå¤±æ•—: {e}")
            return self._fallback_analysis(context, agent_id)
    
    def _rl_analysis(self, context: str, social_context: List[float]) -> Dict:
        """RL ç­–ç•¥åˆ†æ"""
        try:
            strategy = select_strategy(context, "", social_context)
            print(f"  ğŸ“Š RL: é¸æ“‡ç­–ç•¥ = {strategy}")
            
            # é æ¸¬å“è³ªåˆ†æ•¸
            quality_score = self._get_policy_network().predict_quality(context)
            print(f"  ğŸ“Š RL: å“è³ªåˆ†æ•¸ = {quality_score:.2f}")
            
            return {
                'strategy': strategy,
                'quality_score': quality_score,
                'confidence': 0.8  # å¯ä»¥å¾æ¨¡å‹ç²å–
            }
        except Exception as e:
            print(f"âš ï¸ RL åˆ†æå¤±æ•—: {e}")
            return {'strategy': 'analytical', 'quality_score': 0.5, 'confidence': 0.3}
    
    def _gnn_analysis(self, agent_id: str, agent_state: AgentState) -> Dict:
        """GNN ç¤¾æœƒé—œä¿‚åˆ†æ"""
        try:
            # ç²å–ç¤¾æœƒå‘é‡
            social_vector = social_vec(agent_id)
            print(f"  ğŸŒ GNN: ç¤¾æœƒå‘é‡ç¶­åº¦ = {len(social_vector)}")
            
            # ä½¿ç”¨æ–°çš„å½±éŸ¿åŠ›è¨ˆç®—æ–¹æ³•
            influence_score = get_social_influence_score(agent_id)
            print(f"  ğŸŒ GNN: å½±éŸ¿åŠ›åˆ†æ•¸ = {influence_score:.2f}")
            
            # å¦‚æœæœ‰æœ€è¿‘çš„ç™¼è¨€ï¼Œé æ¸¬èªªæœç­–ç•¥
            if hasattr(agent_state, 'last_response') and agent_state.last_response:
                # ç°¡åŒ–çš„æ–‡æœ¬ç‰¹å¾µæå–ï¼ˆå¯¦éš›æ‡‰ä½¿ç”¨ BERTï¼‰
                text_features = np.random.randn(768)  # è‡¨æ™‚ä½¿ç”¨éš¨æ©Ÿç‰¹å¾µ
                persuasion_pred = predict_persuasion(text_features, agent_id)
                
                print(f"  ğŸŒ GNN: é æ¸¬ Delta æ¦‚ç‡ = {persuasion_pred['delta_probability']:.2f}")
                print(f"  ğŸŒ GNN: å»ºè­°ç­–ç•¥ = {persuasion_pred['best_strategy']}")
            else:
                persuasion_pred = {
                    'delta_probability': 0.5,
                    'best_strategy': 'analytical',
                    'strategy_scores': {}
                }
            
            # åˆ†æç«‹å ´è®ŠåŒ–è¶¨å‹¢
            stance_trend = 0.0
            if len(agent_state.persuasion_history) >= 2:
                recent_persuasion = sum(agent_state.persuasion_history[-3:]) / 3
                stance_trend = recent_persuasion - 0.5
            
            print(f"  ğŸŒ GNN: ç«‹å ´è¶¨å‹¢ = {stance_trend:.2f}")
            
            return {
                'social_vector': social_vector,
                'influence_score': influence_score,
                'stance_trend': stance_trend,
                'current_stance': agent_state.current_stance,
                'conviction': agent_state.conviction,
                'persuasion_prediction': persuasion_pred
            }
        except Exception as e:
            print(f"âš ï¸ GNN åˆ†æå¤±æ•—: {e}")
            return {
                'social_vector': [0.0] * 128,
                'influence_score': 0.5,
                'stance_trend': 0.0,
                'current_stance': agent_state.current_stance,
                'conviction': agent_state.conviction,
                'persuasion_prediction': {
                    'delta_probability': 0.5,
                    'best_strategy': 'analytical',
                    'strategy_scores': {}
                }
            }
    
    def _rag_analysis(self, context: str, topic: str) -> Dict:
        """RAG è­‰æ“šæª¢ç´¢åˆ†æ"""
        try:
            # æª¢ç´¢è­‰æ“šæ± 
            retrieval_results = self._get_retriever().retrieve(
                query=context,
                top_k=8
            )
            print(f"  ğŸ“š RAG: æª¢ç´¢åˆ° {len(retrieval_results)} å€‹è­‰æ“š")
            
            # è½‰æ›ç‚ºå­—å…¸æ ¼å¼ä¾› choose_snippet ä½¿ç”¨
            evidence_pool = []
            for result in retrieval_results:
                # æª¢æŸ¥ result æ˜¯å¦å·²ç¶“æ˜¯å­—å…¸ï¼ˆä¾†è‡ª SimpleRetrieverAdapterï¼‰
                if isinstance(result, dict):
                    evidence_dict = {
                        'content': result.get('content', ''),
                        'similarity_score': result.get('score', 0.0),
                        'metadata': result.get('metadata', {}),
                        'doc_id': result.get('doc_id', '')
                    }
                else:
                    # å¦‚æœæ˜¯ç‰©ä»¶ï¼ˆä¾†è‡ª EnhancedRetrieverï¼‰
                    evidence_dict = {
                        'content': getattr(result, 'content', ''),
                        'similarity_score': getattr(result, 'score', 0.0),
                        'metadata': getattr(result, 'metadata', {}),
                        'doc_id': getattr(result, 'doc_id', '')
                    }
                evidence_pool.append(evidence_dict)
            
            # é¸æ“‡æœ€ä½³è­‰æ“š
            best_evidence = choose_snippet(context, evidence_pool)
            print(f"  ğŸ“š RAG: æœ€ä½³è­‰æ“šé•·åº¦ = {len(best_evidence)} å­—")
            
            # åˆ†æè­‰æ“šé¡å‹åˆ†å¸ƒ
            evidence_types = {}
            for result in retrieval_results:
                # å®‰å…¨åœ°ç²å– metadata
                if isinstance(result, dict):
                    metadata = result.get('metadata', {})
                else:
                    metadata = getattr(result, 'metadata', {})
                
                ev_type = metadata.get('type', 'unknown')
                evidence_types[ev_type] = evidence_types.get(ev_type, 0) + 1
            
            print(f"  ğŸ“š RAG: è­‰æ“šé¡å‹åˆ†å¸ƒ = {evidence_types}")
            
            return {
                'evidence_pool': evidence_pool,
                'best_evidence': best_evidence,
                'evidence_types': evidence_types,
                'total_evidence': len(evidence_pool)
            }
        except Exception as e:
            print(f"âš ï¸ RAG åˆ†æå¤±æ•—: {e}")
            return {
                'evidence_pool': [],
                'best_evidence': "No evidence available",
                'evidence_types': {},
                'total_evidence': 0
            }
    
    def _fallback_analysis(self, context: str, agent_id: str) -> Dict:
        """å›é€€åˆ†æ"""
        return {
            'rl': {'strategy': 'analytical', 'quality_score': 0.5, 'confidence': 0.3},
            'gnn': {'social_vector': [0.0] * 128, 'influence_score': 0.5, 
                   'stance_trend': 0.0, 'current_stance': 0.0, 'conviction': 0.7},
            'rag': {'evidence_pool': [], 'best_evidence': "No evidence available",
                   'evidence_types': {}, 'total_evidence': 0},
            'timestamp': time.time()
        }
    
    def fuse_analysis_results(self, analysis_results: Dict, agent_id: str) -> Dict:
        """èåˆåˆ†æçµæœ"""
        rl_result = analysis_results['rl']
        gnn_result = analysis_results['gnn']
        rag_result = analysis_results['rag']
        
        # ç­–ç•¥èª¿æ•´ï¼šçµåˆ RL å’Œ GNN çš„å»ºè­°
        base_strategy = rl_result['strategy']
        gnn_strategy = gnn_result['persuasion_prediction']['best_strategy']
        influence_score = gnn_result['influence_score']
        current_stance = gnn_result['current_stance']
        delta_probability = gnn_result['persuasion_prediction']['delta_probability']
        
        # ç­–ç•¥èåˆé‚è¼¯
        if delta_probability > 0.7:
            # é«˜èªªæœæˆåŠŸç‡ï¼Œå„ªå…ˆä½¿ç”¨ GNN å»ºè­°çš„ç­–ç•¥
            adjusted_strategy = gnn_strategy
            print(f"  ğŸ”„ ç­–ç•¥èª¿æ•´: {base_strategy} â†’ {adjusted_strategy} (åŸºæ–¼é«˜ Delta æ¦‚ç‡)")
        elif influence_score > 0.6 and abs(current_stance) > 0.5:
            # é«˜å½±éŸ¿åŠ› + å¼·ç«‹å ´ = æ›´ç©æ¥µ
            if base_strategy == 'analytical' and gnn_strategy == 'aggressive':
                adjusted_strategy = 'aggressive'
                print(f"  ğŸ”„ ç­–ç•¥èª¿æ•´: {base_strategy} â†’ {adjusted_strategy} (é«˜å½±éŸ¿åŠ›+å¼·ç«‹å ´)")
            else:
                adjusted_strategy = base_strategy
        elif influence_score < 0.4 and abs(current_stance) < 0.3:
            # ä½å½±éŸ¿åŠ› + å¼±ç«‹å ´ = æ›´è¬¹æ…
            if base_strategy == 'aggressive':
                adjusted_strategy = 'defensive'
                print(f"  ğŸ”„ ç­–ç•¥èª¿æ•´: {base_strategy} â†’ {adjusted_strategy} (ä½å½±éŸ¿åŠ›+å¼±ç«‹å ´)")
            else:
                adjusted_strategy = base_strategy
        else:
            # æ¬Šè¡¡ RL å’Œ GNN çš„å»ºè­°
            strategy_scores = gnn_result['persuasion_prediction']['strategy_scores']
            if strategy_scores.get(base_strategy, 0) < 0.2:
                # å¦‚æœ RL é¸æ“‡çš„ç­–ç•¥åœ¨ GNN ä¸­å¾—åˆ†å¾ˆä½ï¼Œè€ƒæ…®åˆ‡æ›
                adjusted_strategy = gnn_strategy
                print(f"  ğŸ”„ ç­–ç•¥èª¿æ•´: {base_strategy} â†’ {adjusted_strategy} (GNN å»ºè­°)")
            else:
                adjusted_strategy = base_strategy
        
        # è­‰æ“šé¸æ“‡ï¼šæ ¹æ“šç­–ç•¥å’Œé æ¸¬çš„èªªæœåŠ›èª¿æ•´
        evidence = rag_result['best_evidence']
        evidence_confidence = min(1.0, rag_result['total_evidence'] / 5.0)
        
        # æ ¹æ“šé æ¸¬çš„ Delta æ¦‚ç‡èª¿æ•´è­‰æ“šä¿¡å¿ƒåº¦
        adjusted_confidence = evidence_confidence * (0.5 + 0.5 * delta_probability)
        
        print(f"  âœ¨ èåˆçµæœ: æœ€çµ‚ç­–ç•¥={adjusted_strategy}, è­‰æ“šä¿¡å¿ƒ={adjusted_confidence:.2f}, Deltaæ¦‚ç‡={delta_probability:.2f}")
        
        return {
            'final_strategy': adjusted_strategy,
            'evidence': evidence,
            'evidence_confidence': adjusted_confidence,
            'social_influence': influence_score,
            'stance_strength': abs(current_stance),
            'conviction': gnn_result['conviction'],
            'delta_probability': delta_probability,
            'gnn_suggested_strategy': gnn_strategy,
            'fusion_timestamp': time.time()
        }
    
    async def generate_response(self, agent_id: str, topic: str, 
                              history: List[str], target_agents: List[str]) -> str:
        """ç”Ÿæˆè¾¯è«–å›è¦†"""
        
        # 1. å¹³è¡Œåˆ†æ
        print(f"\nğŸ”„ Agent {agent_id} é–‹å§‹å¹³è¡Œåˆ†æ...")
        print(f"   ğŸ“ ä¸»é¡Œ: {topic}")
        print(f"   ğŸ“Š æ­·å²å›åˆæ•¸: {len(history)}")
        analysis_start = time.time()
        
        analysis_results = await self.parallel_analysis(agent_id, topic, history)
        
        analysis_time = time.time() - analysis_start
        print(f"âš¡ å¹³è¡Œåˆ†æå®Œæˆ ({analysis_time:.2f}s)")
        
        # 2. èåˆçµæœ
        print(f"ğŸ”€ é–‹å§‹èåˆåˆ†æçµæœ...")
        fused_results = self.fuse_analysis_results(analysis_results, agent_id)
        print(f"âœ… èåˆå®Œæˆ")
        
        # 3. æ§‹å»ºæç¤º
        agent_state = self.agent_states[agent_id]
        recent_history = history[-4:] if history else []
        
        # åˆ†æç›®æ¨™ Agent çš„å¼±é»
        target_analysis = self._analyze_targets(target_agents, history)
        
        prompt = self._build_enhanced_prompt(
            agent_id, topic, recent_history, fused_results, target_analysis
        )
        
        # 4. ç”Ÿæˆå›è¦†
        print(f"ğŸ¤– Agent {agent_id} ä½¿ç”¨ {fused_results['final_strategy']} ç­–ç•¥ç”Ÿæˆå›è¦†...")
        generation_start = time.time()
        response = chat(prompt)
        generation_time = time.time() - generation_start
        print(f"âœ… å›è¦†ç”Ÿæˆå®Œæˆ ({generation_time:.2f}s)")
        
        # æª¢æŸ¥å›æ‡‰æ˜¯å¦è¢«æˆªæ–·ï¼ˆæª¢æŸ¥æ˜¯å¦ä»¥å¥è™Ÿã€å•è™Ÿæˆ–é©šå˜†è™Ÿçµå°¾ï¼‰
        if response and not response.rstrip().endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')):
            print(f"âš ï¸ æª¢æ¸¬åˆ°å›æ‡‰å¯èƒ½è¢«æˆªæ–·ï¼Œå˜—è©¦è£œå……å®Œæ•´...")
            # å¦‚æœå›æ‡‰è¢«æˆªæ–·ï¼Œæ·»åŠ çµå°¾
            response += "ã€‚ç¸½ä¹‹ï¼ŒåŸºæ–¼ä»¥ä¸Šåˆ†æï¼Œæˆ‘å …æŒæˆ‘çš„ç«‹å ´ã€‚"
        
        # 5. è©•ä¼°å›è¦†æ•ˆæœ
        response_effects = self._evaluate_response(response, target_agents)
        
        total_time = time.time() - analysis_start
        print(f"â±ï¸ Agent {agent_id} ç¸½è™•ç†æ™‚é–“: {total_time:.2f}s")
        
        return response
    
    def _analyze_targets(self, target_agents: List[str], history: List[str]) -> Dict:
        """åˆ†æç›®æ¨™ Agent çš„å¼±é»å’Œæ©Ÿæœƒ"""
        target_analysis = {}
        
        for target_id in target_agents:
            if target_id in self.agent_states:
                target_state = self.agent_states[target_id]
                
                # åˆ†æèªªæœæ©Ÿæœƒ
                persuasion_opportunity = 1.0 - target_state.conviction
                
                # åˆ†ææ”»æ“Šæ©Ÿæœƒ
                attack_opportunity = abs(target_state.current_stance)
                
                # åˆ†ææ­·å²è¶¨å‹¢
                recent_persuasion = 0.0
                if target_state.persuasion_history:
                    recent_persuasion = sum(target_state.persuasion_history[-2:]) / 2
                
                target_analysis[target_id] = {
                    'persuasion_opportunity': persuasion_opportunity,
                    'attack_opportunity': attack_opportunity,
                    'recent_persuasion': recent_persuasion,
                    'stance': target_state.current_stance,
                    'conviction': target_state.conviction
                }
        
        return target_analysis
    
    def _build_enhanced_prompt(self, agent_id: str, topic: str, history: List[str],
                              fused_results: Dict, target_analysis: Dict) -> str:
        """æ§‹å»ºå¢å¼·æç¤º"""
        
        agent_state = self.agent_states[agent_id]
        strategy = fused_results['final_strategy']
        evidence = fused_results['evidence']
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºç¬¬ä¸€å›åˆ
        is_first_round = len(history) == 0
        
        # æ­·å²å°è©±
        history_text = '\n'.join(f"Turn {i+1}: {turn}" for i, turn in enumerate(history))
        
        # åˆ†æå·²ä½¿ç”¨çš„è«–é»ï¼ˆé¿å…é‡è¤‡ï¼‰
        used_arguments = self._extract_used_arguments(history, agent_id)
        
        # ç›®æ¨™åˆ†æï¼ˆç¬¬ä¸€å›åˆä¸éœ€è¦ï¼‰
        target_info = ""
        if not is_first_round:
            for target_id, analysis in target_analysis.items():
                target_info += f"\n- {target_id}: ç«‹å ´{analysis['stance']:.2f}, ä¿¡å¿µ{analysis['conviction']:.2f}, èªªæœæ©Ÿæœƒ{analysis['persuasion_opportunity']:.2f}"
        
        # å¢å¼·çš„ç­–ç•¥æŒ‡å°
        strategy_guidance = {
            'aggressive': "æ¡ç”¨æ‰¹åˆ¤æ€§åˆ†æç­–ç•¥ï¼šæ·±å…¥å‰–æå°æ–¹è«–é»çš„é‚è¼¯ç¼ºé™·ï¼Œç”¨æœ‰åŠ›çš„åä¾‹å’Œæ•¸æ“šæŒ‘æˆ°å…¶æ ¸å¿ƒå‡è¨­ã€‚",
            'defensive': "æ¡ç”¨ç©©å¥è«–è­‰ç­–ç•¥ï¼šéå›ºè‡ªå·±çš„æ ¸å¿ƒè«–é»ï¼Œç³»çµ±æ€§åœ°å›æ‡‰è³ªç–‘ï¼Œç”¨æ›´å¤šè­‰æ“šå¼·åŒ–ç«‹å ´ã€‚",
            'analytical': "æ¡ç”¨ç†æ€§åˆ†æç­–ç•¥ï¼šé‹ç”¨é‚è¼¯æ¨ç†ã€å¯¦è­‰æ•¸æ“šå’Œæ¡ˆä¾‹ç ”ç©¶ï¼Œå®¢è§€åœ°è©•ä¼°å„ç¨®è§€é»çš„å„ªåŠ£ã€‚",
            'empathetic': "æ¡ç”¨å»ºè¨­æ€§å°è©±ç­–ç•¥ï¼šç†è§£å°æ–¹çš„åˆç†é—œåˆ‡ï¼Œå°‹æ‰¾å…±åŒé»ï¼Œæå‡ºå…¼é¡§å„æ–¹åˆ©ç›Šçš„è§£æ±ºæ–¹æ¡ˆã€‚"
        }
        
        # è¾¯è«–é¢¨æ ¼æç¤º
        if is_first_round:
            debate_style = """
é€™æ˜¯é—œæ–¼å…¬å…±è­°é¡Œçš„ç†æ€§è¾¯è«–ï¼Œä½ éœ€è¦ï¼š
- æ¸…æ¥šé™³è¿°ä½ å°è­°é¡Œçš„ç«‹å ´ï¼ˆæ”¯æŒæˆ–åå°ï¼‰
- æå‡ºä½ çš„æ ¸å¿ƒè«–é»å’Œç†ç”±
- ä½¿ç”¨äº‹å¯¦å’Œé‚è¼¯æ”¯æŒä½ çš„è§€é»
- å±•ç¾æ‰¹åˆ¤æ€§æ€ç¶­èƒ½åŠ›
- ä¸è¦æåŠå…¶ä»–åƒèˆ‡è€…ï¼ˆå› ç‚ºä½ é‚„æ²’è½éä»–å€‘çš„ç™¼è¨€ï¼‰
"""
            round_instruction = """
ç¬¬ä¸€å›åˆè¦æ±‚ï¼š
1. æ˜ç¢ºè¡¨æ˜ä½ æ˜¯æ”¯æŒé‚„æ˜¯åå°è©²è­°é¡Œ
2. æå‡º3-4å€‹æ ¸å¿ƒè«–é»
3. ä½¿ç”¨å…·é«”äº‹å¯¦å’Œæ•¸æ“šæ”¯æŒä½ çš„ç«‹å ´
4. å¾ç¤¾æœƒå½±éŸ¿ã€ç¶“æ¿Ÿæ•ˆç›Šã€é•·é ç™¼å±•ç­‰è§’åº¦åˆ†æ
5. ä¸è¦æåŠå…¶ä»–åƒèˆ‡è€…
6. å­—æ•¸è¦æ±‚ï¼š200-250å­—
7. å¿…é ˆå®Œæˆå®Œæ•´çš„è«–è¿°ï¼Œä¸è¦ä¸­é€”æˆªæ–·
"""
        else:
            # æ ¹æ“šå›åˆæ•¸èª¿æ•´ç­–ç•¥
            round_num = len([h for h in history if agent_id in h]) + 1
            if round_num >= 3 and agent_state.conviction < 0.4:
                debate_style = """
ç¶“éæ·±å…¥è¨è«–ï¼Œä½ é–‹å§‹é‡æ–°æ€è€ƒé€™å€‹è­°é¡Œï¼š
- æ‰¿èªå°æ–¹æŸäº›è«–é»ç¢ºå¯¦æœ‰é“ç†
- åæ€è‡ªå·±ç«‹å ´çš„å±€é™æ€§
- å˜—è©¦å°‹æ‰¾ä¸­é–“ç«‹å ´æˆ–å¦¥å”æ–¹æ¡ˆ
- å±•ç¾é–‹æ”¾å’Œç†æ€§çš„æ…‹åº¦
"""
            elif round_num >= 4:
                debate_style = """
è¾¯è«–é€²å…¥ç¸½çµéšæ®µï¼Œä½ éœ€è¦ï¼š
- æ•´åˆå„æ–¹è§€é»ï¼Œæå‡ºå…¨é¢çš„åˆ†æ
- æŒ‡å‡ºæ ¸å¿ƒåˆ†æ­§é»å’Œå…±è­˜
- æå‡ºå¯è¡Œçš„è§£æ±ºæ–¹æ¡ˆæˆ–å»ºè­°
- ç‚ºé€™å€‹å…¬å…±è­°é¡Œçš„è¨è«–åšå‡ºå»ºè¨­æ€§è²¢ç»
"""
            else:
                debate_style = """
é€™æ˜¯ä¸€å ´æ·±å…¥çš„å…¬å…±è­°é¡Œè¾¯è«–ï¼Œä½ éœ€è¦ï¼š
- å›æ‡‰å°æ–¹çš„å…·é«”è«–é»
- æä¾›æ›´å¤šè­‰æ“šå’Œåˆ†æ
- å¾ä¸åŒè§’åº¦æ·±åŒ–ä½ çš„è«–è­‰
- ä¿æŒç†æ€§å’Œå°ˆæ¥­çš„è¨è«–æ°›åœ
"""
            
            # é¿å…é‡è¤‡çš„æŒ‡å°
            avoid_repetition = ""
            if used_arguments:
                avoid_repetition = f"""
æ³¨æ„ï¼šä½ å·²ç¶“è¨è«–éä»¥ä¸‹æ–¹é¢ï¼Œè«‹æ¢è¨æ–°çš„è§’åº¦ï¼š
{chr(10).join(f"- {arg}" for arg in used_arguments[:3])}

å˜—è©¦å¾å…¶ä»–ç¶­åº¦åˆ†æï¼Œå¦‚ï¼šç¤¾æœƒå…¬å¹³ã€å¯æŒçºŒç™¼å±•ã€åœ‹éš›æ¯”è¼ƒã€æ­·å²ç¶“é©—ç­‰ã€‚
"""
            
            round_instruction = f"""
è¾¯è«–è¦æ±‚ï¼š
1. å›æ‡‰å°æ–¹çš„æ ¸å¿ƒè«–é»ï¼ŒæŒ‡å‡ºé‚è¼¯æ¼æ´æˆ–æä¾›åè­‰
2. æ·±åŒ–ä½ çš„è«–è­‰ï¼Œæä¾›æ–°çš„è¦–è§’å’Œè­‰æ“š
3. ä½¿ç”¨ã€Œä½†æ˜¯ã€ã€ã€Œç„¶è€Œã€ã€ã€Œå¦ä¸€æ–¹é¢ã€ç­‰é€£æ¥è©
4. å¼•ç”¨å…·é«”æ¡ˆä¾‹æˆ–æ•¸æ“šæ™‚ä½¿ç”¨ [CITE] æ¨™è¨˜
5. ä¿æŒå®¢è§€ç†æ€§ï¼Œé¿å…äººèº«æ”»æ“Š
6. å¦‚æœè¢«èªªæœï¼Œå¯ä»¥é©ç•¶èª¿æ•´ç«‹å ´
7. é¿å…é‡è¤‡å·²ç¶“è¨è«–éçš„å…§å®¹
8. å­—æ•¸è¦æ±‚ï¼š200-250å­—
9. å¿…é ˆå®Œæˆå®Œæ•´çš„è«–è¿°ï¼Œç¢ºä¿è«–é»æœ‰é ­æœ‰å°¾

{avoid_repetition}
"""
        
        # æ§‹å»ºæç¤º
        if is_first_round:
            return f"""ä½ æ­£åœ¨åƒèˆ‡ä¸€å ´é—œæ–¼ã€Œ{topic}ã€çš„å…¬å…±è­°é¡Œè¾¯è«–ã€‚

{debate_style}

ä½ çš„è§’è‰²è¨­å®šï¼š
- ç«‹å ´å‚¾å‘ï¼š{agent_state.current_stance:.2f} (æ­£å€¼å‚¾å‘æ”¯æŒï¼Œè² å€¼å‚¾å‘åå°)
- å …å®šç¨‹åº¦ï¼š{agent_state.conviction:.2f} (è¶Šé«˜è¶Šä¸æ˜“æ”¹è®Šç«‹å ´)
- è«–è­‰é¢¨æ ¼ï¼š{strategy}

å¯ç”¨è«–æ“šï¼š
{evidence}

{round_instruction}

è«‹ç™¼è¡¨ä½ çš„è§€é»ï¼š"""
        else:
            return f"""ä½ æ­£åœ¨åƒèˆ‡ä¸€å ´é—œæ–¼ã€Œ{topic}ã€çš„å…¬å…±è­°é¡Œè¾¯è«–ã€‚

{debate_style}

ä½ çš„ç•¶å‰ç‹€æ…‹ï¼š
- ç«‹å ´å‚¾å‘ï¼š{agent_state.current_stance:.2f} (æ­£å€¼å‚¾å‘æ”¯æŒï¼Œè² å€¼å‚¾å‘åå°)
- å …å®šç¨‹åº¦ï¼š{agent_state.conviction:.2f} (è¶Šé«˜è¶Šä¸æ˜“æ”¹è®Šç«‹å ´)
- è«–è­‰é¢¨æ ¼ï¼š{strategy}

è¨è«–è¨˜éŒ„ï¼š
{history_text}

å¯ç”¨è«–æ“šï¼š
{evidence}

å…¶ä»–åƒèˆ‡è€…ç‹€æ…‹ï¼š{target_info}

è«–è­‰ç­–ç•¥ï¼š{strategy_guidance.get(strategy, '')}

{round_instruction}

è«‹ç™¼è¡¨ä½ çš„è§€é»ï¼š"""
    
    def _extract_used_arguments(self, history: List[str], agent_id: str) -> List[str]:
        """æå–å·²ä½¿ç”¨çš„è«–é»é—œéµè©"""
        used_arguments = []
        
        # ç°¡å–®çš„é—œéµè©æå–
        keywords = ['ç¶“æ¿Ÿ', 'å¤±æ¥­ç‡', 'å¤–äº¤', 'è²¿æ˜“', 'ç’°å¢ƒ', 'æ°£å€™', 'å®‰å…¨', 'æ”¿ç­–', 
                   'è²¡æ”¿', 'èµ¤å­—', 'åœ‹éš›', 'é ˜å°', 'ç¤¾æœƒ', 'åˆ†è£‚']
        
        for turn in history:
            if agent_id in turn:
                for keyword in keywords:
                    if keyword in turn and keyword not in used_arguments:
                        used_arguments.append(keyword)
        
        return used_arguments
    
    def _evaluate_response(self, response: str, target_agents: List[str]) -> Dict:
        """è©•ä¼°å›è¦†çš„èªªæœåŠ›å’Œæ”»æ“Šæ€§"""
        
        # ä¸­è‹±æ–‡é—œéµè©è©•ä¼°
        persuasion_indicators = [
            'however', 'consider', 'understand', 'perspective', 'common',
            'ä½†æ˜¯', 'è€ƒæ…®', 'ç†è§£', 'è§€é»', 'å…±åŒ', 'èªåŒ', 'åŒæ„'
        ]
        attack_indicators = [
            'wrong', 'flawed', 'mistake', 'ignore', 'fail',
            'éŒ¯èª¤', 'ç¼ºé™·', 'è¬¬èª¤', 'å¿½è¦–', 'å¤±æ•—', 'è’è¬¬', 'ä¸åˆç†'
        ]
        evidence_indicators = [
            '[CITE]', 'study', 'research', 'data', 'evidence',
            'ç ”ç©¶', 'æ•¸æ“š', 'è­‰æ“š', 'äº‹å¯¦', 'çµ±è¨ˆ', 'å ±å‘Š', 'èª¿æŸ¥'
        ]
        
        # è¨ˆç®—åˆ†æ•¸ï¼ˆä½¿ç”¨æ›´æ•æ„Ÿçš„è¨ˆç®—æ–¹å¼ï¼‰
        response_lower = response.lower()
        persuasion_count = sum(1 for indicator in persuasion_indicators if indicator in response_lower)
        attack_count = sum(1 for indicator in attack_indicators if indicator in response_lower)
        evidence_count = sum(1 for indicator in evidence_indicators if indicator in response_lower)
        
        # èª¿æ•´åˆ†æ•¸è¨ˆç®—ï¼Œä½¿å…¶æ›´å®¹æ˜“ç²å¾—éé›¶åˆ†æ•¸
        persuasion_score = min(1.0, persuasion_count * 0.3)
        attack_score = min(1.0, attack_count * 0.4)
        evidence_score = min(1.0, evidence_count * 0.35)
        
        # é•·åº¦åˆ†æ•¸
        word_count = len(response.split())
        length_score = min(1.0, word_count / 80)
        
        return {
            'persuasion_score': persuasion_score,
            'attack_score': attack_score,
            'evidence_score': evidence_score,
            'length_score': length_score
        }
    
    async def run_debate_round(self, round_number: int, topic: str, 
                             agent_order: List[str]) -> DebateRound:
        """åŸ·è¡Œä¸€è¼ªè¾¯è«–"""
        
        print(f"\nğŸ­ é–‹å§‹ç¬¬ {round_number} è¼ªè¾¯è«–")
        print(f"ä¸»é¡Œ: {topic}")
        print(f"ç™¼è¨€é †åº: {' â†’ '.join(agent_order)}")
        
        # ç²å–æ‰€æœ‰ä¹‹å‰çš„æ­·å²è¨˜éŒ„
        all_history = []
        for past_round in self.debate_history:
            for response in past_round.history:
                all_history.append(f"{response['agent_id']}: {response['content']}")
        
        # ç•¶å‰å›åˆçš„å›æ‡‰
        round_responses = []
        
        for i, agent_id in enumerate(agent_order):
            print(f"\n--- Agent {agent_id} ç™¼è¨€ ---")
            
            # ç¢ºå®šç›®æ¨™å°æ‰‹
            other_agents = [aid for aid in agent_order if aid != agent_id]
            
            # çµ„åˆæ­·å²ï¼šä¹‹å‰æ‰€æœ‰å›åˆ + ç•¶å‰å›åˆå·²ç™¼è¨€
            current_history = all_history + [f"{r['agent_id']}: {r['content']}" for r in round_responses]
            
            # ç”Ÿæˆå›è¦†
            response = await self.generate_response(
                agent_id, topic, 
                current_history, 
                other_agents
            )
            
            # è©•ä¼°æ•ˆæœ
            effects = self._evaluate_response(response, other_agents)
            
            # è¨˜éŒ„å›è¦†
            round_responses.append({
                'agent_id': agent_id,
                'content': response,
                'effects': effects,
                'timestamp': time.time()
            })
            
            print(f"Agent {agent_id}: {response[:100]}...")
            print(f"æ•ˆæœè©•ä¼°: èªªæœ{effects['persuasion_score']:.2f}, æ”»æ“Š{effects['attack_score']:.2f}")
            
            # æ›´æ–°å…¶ä»– Agent çš„ç‹€æ…‹
            for target_id in other_agents:
                if target_id in self.agent_states:
                    self.agent_states[target_id].update_stance(
                        effects['persuasion_score'],
                        effects['attack_score']
                    )
        
        # å‰µå»ºå›åˆè¨˜éŒ„
        debate_round = DebateRound(
            round_number=round_number,
            topic=topic,
            agent_states=dict(self.agent_states),
            history=round_responses
        )
        
        self.debate_history.append(debate_round)
        
        # é¡¯ç¤ºå›åˆçµæœ
        self._display_round_summary(debate_round)
        
        return debate_round
    
    def _display_round_summary(self, debate_round: DebateRound):
        """é¡¯ç¤ºå›åˆç¸½çµ"""
        print(f"\nğŸ“Š ç¬¬ {debate_round.round_number} è¼ªç¸½çµ")
        print("=" * 50)
        
        for agent_id, state in debate_round.agent_states.items():
            print(f"Agent {agent_id}:")
            print(f"  ç«‹å ´: {state.current_stance:+.2f} | ä¿¡å¿µ: {state.conviction:.2f}")
            if state.persuasion_history:
                avg_persuasion = sum(state.persuasion_history[-3:]) / min(3, len(state.persuasion_history))
                print(f"  è¿‘æœŸè¢«èªªæœåº¦: {avg_persuasion:.2f}")
    
    def get_debate_summary(self) -> Dict:
        """ç²å–è¾¯è«–ç¸½çµå’Œå‹è² åˆ¤å®š"""
        if not self.debate_history:
            return {"message": "å°šæœªé–‹å§‹è¾¯è«–"}
        
        # çµ±è¨ˆæŠ•é™æƒ…æ³
        surrendered_agents = [aid for aid, state in self.agent_states.items() 
                            if state.has_surrendered]
        
        # è¨ˆç®—æ¯å€‹ Agent çš„ç¶œåˆå¾—åˆ†
        agent_scores = {}
        for agent_id, state in self.agent_states.items():
            # åŸºç¤åˆ†æ•¸
            score = 0
            
            # ç«‹å ´å …å®šåº¦å¾—åˆ†ï¼ˆç«‹å ´è¶Šæ¥µç«¯ä¸”ä¿¡å¿µè¶Šå¼·å¾—åˆ†è¶Šé«˜ï¼‰
            stance_score = abs(state.current_stance) * state.conviction * 30
            score += stance_score
            
            # èªªæœä»–äººå¾—åˆ†ï¼ˆæ ¹æ“šå…¶ä»–äººçš„æŠ•é™å’Œç«‹å ´æ”¹è®Šï¼‰
            persuasion_score = 0
            for other_id, other_state in self.agent_states.items():
                if other_id != agent_id:
                    if other_state.has_surrendered:
                        persuasion_score += 20
                    # è¨ˆç®—å°å…¶ä»–äººçš„å½±éŸ¿
                    if len(other_state.persuasion_history) > 0:
                        avg_persuasion = sum(other_state.persuasion_history) / len(other_state.persuasion_history)
                        persuasion_score += avg_persuasion * 10
            score += persuasion_score
            
            # æŠ—å£“èƒ½åŠ›å¾—åˆ†ï¼ˆè¢«æ”»æ“Šä½†ä»ä¿æŒç«‹å ´ï¼‰
            if len(state.attack_history) > 0:
                avg_attack = sum(state.attack_history) / len(state.attack_history)
                resistance_score = (1 - avg_attack) * state.conviction * 20
                score += resistance_score
            
            # æŠ•é™æ‰£åˆ†
            if state.has_surrendered:
                score -= 50
            
            agent_scores[agent_id] = score
        
        # åˆ¤å®šç²å‹è€…
        winner = max(agent_scores.keys(), key=lambda x: agent_scores[x])
        
        # ç”Ÿæˆç¸½çµå ±å‘Š
        summary = {
            "total_rounds": len(self.debate_history),
            "winner": winner,
            "scores": agent_scores,
            "surrendered_agents": surrendered_agents,
            "final_states": {},
            "verdict": ""
        }
        
        # æ·»åŠ æœ€çµ‚ç‹€æ…‹
        for aid, state in self.agent_states.items():
            summary["final_states"][aid] = {
                "stance": state.current_stance,
                "conviction": state.conviction,
                "has_surrendered": state.has_surrendered,
                "final_position": "æ”¯æŒ" if state.current_stance > 0 else "åå°"
            }
        
        # ç”Ÿæˆè£æ±ºè©
        if len(surrendered_agents) > 0:
            summary["verdict"] = f"ğŸ† {winner} ç²å¾—å£“å€’æ€§å‹åˆ©ï¼æˆåŠŸèªªæœ {', '.join(surrendered_agents)} æŠ•é™ã€‚"
        else:
            score_diff = agent_scores[winner] - sorted(agent_scores.values())[-2]
            if score_diff > 30:
                summary["verdict"] = f"ğŸ† {winner} ä»¥æ˜é¡¯å„ªå‹¢ç²å‹ï¼å±•ç¾äº†å“è¶Šçš„è¾¯è«–æŠ€å·§ã€‚"
            else:
                summary["verdict"] = f"ğŸ† {winner} éšªå‹ï¼é€™æ˜¯ä¸€å ´å‹¢å‡åŠ›æ•µçš„ç²¾å½©è¾¯è«–ã€‚"
        
        return summary

# ä¾¿åˆ©å‡½æ•¸
def create_parallel_orchestrator():
    """å‰µå»ºå¹³è¡Œå”èª¿å™¨"""
    return ParallelOrchestrator() 
"""
RL è¨“ç·´ Pipeline
æ•´åˆæ•¸æ“šè™•ç†ã€æ¨¡å‹è¨“ç·´å’Œè©•ä¼°çš„å®Œæ•´æµç¨‹
"""

import sys
from pathlib import Path
import argparse
import time
from typing import Optional

# æ·»åŠ  src è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent))

from data_processor import RLDataProcessor
from trainer import RLTrainer

class RLPipeline:
    """RL è¨“ç·´ Pipeline"""
    
    def __init__(self, 
                 input_data: str = "data/raw/pairs.jsonl",
                 processed_data: str = "data/rl/rl_pairs.csv",
                 model_output: str = "data/models/policy",
                 force_reprocess: bool = False):
        
        self.input_data = Path(input_data)
        self.processed_data = Path(processed_data)
        self.model_output = Path(model_output)
        self.force_reprocess = force_reprocess
        
        print("ğŸš€ RL è¨“ç·´ Pipeline åˆå§‹åŒ–")
        print(f"  è¼¸å…¥æ•¸æ“š: {self.input_data}")
        print(f"  è™•ç†å¾Œæ•¸æ“š: {self.processed_data}")
        print(f"  æ¨¡å‹è¼¸å‡º: {self.model_output}")
        print(f"  å¼·åˆ¶é‡æ–°è™•ç†: {self.force_reprocess}")
    
    def check_data_exists(self) -> bool:
        """æª¢æŸ¥è™•ç†å¾Œçš„æ•¸æ“šæ˜¯å¦å­˜åœ¨"""
        return self.processed_data.exists() and not self.force_reprocess
    
    def step1_process_data(self) -> bool:
        """æ­¥é©Ÿ1: æ•¸æ“šè™•ç†"""
        print("\n" + "="*60)
        print("ğŸ“Š æ­¥é©Ÿ 1: æ•¸æ“šè™•ç†")
        print("="*60)
        
        if self.check_data_exists():
            print(f"âœ… ç™¼ç¾å·²è™•ç†çš„æ•¸æ“š: {self.processed_data}")
            print("â­ï¸  è·³éæ•¸æ“šè™•ç†æ­¥é©Ÿ")
            return True
        
        try:
            processor = RLDataProcessor(
                input_path=str(self.input_data),
                output_path=str(self.processed_data)
            )
            
            df = processor.run()
            
            if len(df) == 0:
                print("âŒ æ²’æœ‰ç”Ÿæˆæœ‰æ•ˆçš„è¨“ç·´æ¨£æœ¬")
                return False
            
            print(f"âœ… æ•¸æ“šè™•ç†å®Œæˆï¼Œç”Ÿæˆ {len(df)} å€‹è¨“ç·´æ¨£æœ¬")
            return True
            
        except Exception as e:
            print(f"âŒ æ•¸æ“šè™•ç†å¤±æ•—: {e}")
            return False
    
    def step2_train_model(self) -> bool:
        """æ­¥é©Ÿ2: æ¨¡å‹è¨“ç·´"""
        print("\n" + "="*60)
        print("ğŸ¯ æ­¥é©Ÿ 2: æ¨¡å‹è¨“ç·´")
        print("="*60)
        
        try:
            trainer = RLTrainer(
                data_path=str(self.processed_data),
                output_dir=str(self.model_output)
            )
            
            results = trainer.train()
            
            print(f"âœ… æ¨¡å‹è¨“ç·´å®Œæˆ")
            print(f"  è¨“ç·´æ™‚é–“: {results['training_time']:.2f} ç§’")
            print(f"  æ¨¡å‹ä¿å­˜è‡³: {results['model_path']}")
            
            # é¡¯ç¤ºè©•ä¼°çµæœ
            eval_results = results['eval_results']
            print(f"  æœ€çµ‚ MSE: {eval_results['eval_mse']:.4f}")
            print(f"  æœ€çµ‚ MAE: {eval_results['eval_mae']:.4f}")
            print(f"  æœ€çµ‚ RÂ²: {eval_results['eval_r2']:.4f}")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¨“ç·´å¤±æ•—: {e}")
            return False
    
    def step3_validate_model(self) -> bool:
        """æ­¥é©Ÿ3: æ¨¡å‹é©—è­‰"""
        print("\n" + "="*60)
        print("ğŸ” æ­¥é©Ÿ 3: æ¨¡å‹é©—è­‰")
        print("="*60)
        
        try:
            # æª¢æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            model_files = [
                self.model_output / "config.json",
                self.model_output / "pytorch_model.bin",
                self.model_output / "tokenizer.json"
            ]
            
            missing_files = [f for f in model_files if not f.exists()]
            if missing_files:
                print(f"âŒ ç¼ºå°‘æ¨¡å‹æ–‡ä»¶: {missing_files}")
                return False
            
            # å˜—è©¦è¼‰å…¥æ¨¡å‹
            print("ğŸ”„ é©—è­‰æ¨¡å‹è¼‰å…¥...")
            from policy_network import PolicyNetwork
            
            policy_net = PolicyNetwork(model_path=str(self.model_output))
            
            # æ¸¬è©¦ç­–ç•¥é¸æ“‡
            test_query = "Should we implement universal healthcare?"
            strategy = policy_net.select_strategy(test_query)
            print(f"âœ… ç­–ç•¥é¸æ“‡æ¸¬è©¦é€šé: {strategy}")
            
            # æ¸¬è©¦å“è³ªé æ¸¬
            quality_score = policy_net.predict_quality(test_query)
            print(f"âœ… å“è³ªé æ¸¬æ¸¬è©¦é€šé: {quality_score:.3f}")
            
            # æ¸¬è©¦ç‰‡æ®µé¸æ“‡
            test_pool = [
                {'content': 'Universal healthcare reduces costs', 'similarity_score': 0.8},
                {'content': 'Private healthcare is more efficient', 'similarity_score': 0.6}
            ]
            
            from policy_network import choose_snippet
            chosen = choose_snippet(test_query, test_pool, policy_net)
            print(f"âœ… ç‰‡æ®µé¸æ“‡æ¸¬è©¦é€šé: {chosen[:50]}...")
            
            print("âœ… æ¨¡å‹é©—è­‰å®Œæˆï¼Œæ‰€æœ‰åŠŸèƒ½æ­£å¸¸")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹é©—è­‰å¤±æ•—: {e}")
            return False
    
    def run(self) -> bool:
        """åŸ·è¡Œå®Œæ•´çš„è¨“ç·´ pipeline"""
        print("ğŸš€ é–‹å§‹ RL è¨“ç·´ Pipeline")
        start_time = time.time()
        
        # æ­¥é©Ÿ1: æ•¸æ“šè™•ç†
        if not self.step1_process_data():
            print("âŒ Pipeline å¤±æ•—æ–¼æ•¸æ“šè™•ç†æ­¥é©Ÿ")
            return False
        
        # æ­¥é©Ÿ2: æ¨¡å‹è¨“ç·´
        if not self.step2_train_model():
            print("âŒ Pipeline å¤±æ•—æ–¼æ¨¡å‹è¨“ç·´æ­¥é©Ÿ")
            return False
        
        # æ­¥é©Ÿ3: æ¨¡å‹é©—è­‰
        if not self.step3_validate_model():
            print("âŒ Pipeline å¤±æ•—æ–¼æ¨¡å‹é©—è­‰æ­¥é©Ÿ")
            return False
        
        # å®Œæˆ
        total_time = time.time() - start_time
        print("\n" + "="*60)
        print("ğŸ‰ RL è¨“ç·´ Pipeline å®Œæˆï¼")
        print("="*60)
        print(f"â±ï¸  ç¸½è€—æ™‚: {total_time:.2f} ç§’")
        print(f"ğŸ“ æ¨¡å‹ä¿å­˜ä½ç½®: {self.model_output}")
        print(f"ğŸ“Š è™•ç†å¾Œæ•¸æ“š: {self.processed_data}")
        
        return True

def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="RL è¨“ç·´ Pipeline")
    parser.add_argument("--input", default="data/raw/pairs.jsonl", 
                       help="è¼¸å…¥æ•¸æ“šè·¯å¾‘")
    parser.add_argument("--output", default="data/models/policy", 
                       help="æ¨¡å‹è¼¸å‡ºè·¯å¾‘")
    parser.add_argument("--force-reprocess", action="store_true",
                       help="å¼·åˆ¶é‡æ–°è™•ç†æ•¸æ“š")
    
    args = parser.parse_args()
    
    # å‰µå»º pipeline
    pipeline = RLPipeline(
        input_data=args.input,
        model_output=args.output,
        force_reprocess=args.force_reprocess
    )
    
    # åŸ·è¡Œ pipeline
    success = pipeline.run()
    
    if success:
        print("\nâœ… Pipeline åŸ·è¡ŒæˆåŠŸï¼")
        exit(0)
    else:
        print("\nâŒ Pipeline åŸ·è¡Œå¤±æ•—ï¼")
        exit(1)

if __name__ == "__main__":
    main() 
"""
RL è¨“ç·´ä¸»ç¨‹å¼
è¨“ç·´ç­–ç•¥ç¶²è·¯ä»¥é¸æ“‡æœ€ä½³è¾¯è«–ç­–ç•¥
"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.rl.trainer import RLTrainer
from src.rl.data_processor import RLDataProcessor
from src.utils.config_loader import ConfigLoader
import argparse
import torch
import numpy as np
import random

def set_seed(seed: int = 517466):
    """è¨­ç½®æ‰€æœ‰éš¨æ©Ÿç¨®å­ä»¥ç¢ºä¿å¯é‡è¤‡æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

def main():
    """ä¸»è¨“ç·´å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="è¨“ç·´ RL ç­–ç•¥ç¶²è·¯")
    parser.add_argument("--data_path", type=str, default="data/rl/rl_pairs.csv", help="è¨“ç·´æ•¸æ“šè·¯å¾‘")
    parser.add_argument("--model_name", type=str, default="distilbert-base-uncased", help="åŸºç¤æ¨¡å‹åç¨±")
    parser.add_argument("--output_dir", type=str, default="data/models/policy", help="è¼¸å‡ºç›®éŒ„")
    parser.add_argument("--epochs", type=int, default=3, help="è¨“ç·´è¼ªæ•¸")
    parser.add_argument("--batch_size", type=int, default=16, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--learning_rate", type=float, default=5e-5, help="å­¸ç¿’ç‡")
    parser.add_argument("--seed", type=int, default=517466, help="éš¨æ©Ÿç¨®å­")
    parser.add_argument("--process_data", action="store_true", help="æ˜¯å¦å…ˆè™•ç†åŸå§‹æ•¸æ“š")
    args = parser.parse_args()
    
    print("=" * 50)
    print("ğŸš€ RL è¨“ç·´ç¨‹å¼")
    print("=" * 50)
    
    # è¨­ç½®éš¨æ©Ÿç¨®å­
    set_seed(args.seed)
    
    # è¼‰å…¥é…ç½®
    config = ConfigLoader.load("rl")
    
    # å¦‚æœéœ€è¦ï¼Œå…ˆè™•ç†æ•¸æ“š
    if args.process_data or not Path(args.data_path).exists():
        print("\nğŸ“Š è™•ç†åŸå§‹æ•¸æ“š...")
        raw_data_path = config.get("data_processing", {}).get("input_path", "data/raw/pairs.jsonl")
        
        # ä½¿ç”¨ RLDataProcessor é¡
        processor = RLDataProcessor(
            input_path=raw_data_path,
            output_path=args.data_path
        )
        processor.run()  # ä½¿ç”¨ run() æ–¹æ³•ï¼Œå®ƒæœƒè™•ç†ä¸¦ä¿å­˜æ•¸æ“š
        print("âœ… æ•¸æ“šè™•ç†å®Œæˆ")
    
    # åˆä½µé…ç½®å’Œå‘½ä»¤è¡Œåƒæ•¸
    training_config = config.get("training", {})
    model_config = config.get("policy_network", {})
    
    # å‰µå»ºè¨“ç·´å™¨
    trainer = RLTrainer(
        data_path=args.data_path,
        model_name=args.model_name or model_config.get("base_model", "distilbert-base-uncased"),
        output_dir=args.output_dir,
        max_length=training_config.get("max_length", 512)
    )
    
    print(f"\né…ç½®åƒæ•¸:")
    print(f"  - æ•¸æ“šè·¯å¾‘: {args.data_path}")
    print(f"  - æ¨¡å‹åç¨±: {trainer.model_name}")
    print(f"  - è¼¸å‡ºç›®éŒ„: {trainer.output_dir}")
    print(f"  - è¨“ç·´è¼ªæ•¸: {args.epochs}")
    print(f"  - æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"  - å­¸ç¿’ç‡: {args.learning_rate}")
    print(f"  - éš¨æ©Ÿç¨®å­: {args.seed}")
    print("-" * 50)
    
    try:
        # åŸ·è¡Œè¨“ç·´
        results = trainer.train()
        
        print("\nâœ… RL è¨“ç·´å®Œæˆï¼")
        print("\nğŸ“Š è¨“ç·´çµæœ:")
        for key, value in results['eval_results'].items():
            if isinstance(value, float):
                print(f"  - {key}: {value:.4f}")
        print(f"  - è¨“ç·´æ™‚é–“: {results['training_time']:.2f} ç§’")
        print(f"  - æ¨¡å‹ä¿å­˜æ–¼: {results['model_path']}")
        
    except Exception as e:
        print(f"\nâŒ è¨“ç·´å¤±æ•—: {e}")
        raise

if __name__ == "__main__":
    main() 
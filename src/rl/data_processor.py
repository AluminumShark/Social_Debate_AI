"""
RL è¨“ç·´æ•¸æ“šè™•ç†æ¨¡çµ„
è™•ç† CMV æ•¸æ“šä¸¦ç”Ÿæˆè¨“ç·´æ¨£æœ¬
"""

import json
import pandas as pd
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import re
from tqdm import tqdm

class RLDataProcessor:
    """RL è¨“ç·´æ•¸æ“šè™•ç†å™¨"""
    
    def __init__(self, input_path: str = "data/raw/pairs.jsonl", 
                 output_path: str = "data/rl/rl_pairs.csv"):
        self.input_path = Path(input_path)
        self.output_path = Path(output_path)
        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        
    def clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬"""
        if not text:
            return ""
        
        # ç§»é™¤éé•·çš„æ–‡æœ¬
        if len(text) > 2000:
            text = text[:2000]
        
        # ç§»é™¤å¤šé¤˜çš„ç©ºç™½å’Œæ›è¡Œ
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ä½†ä¿ç•™æ¨™é»
        text = re.sub(r'[^\w\s.,!?;:()\-\'"@#$%]', '', text)
        
        return text
    
    def calculate_quality_score(self, comment: Dict, submission: Dict, 
                              is_delta: bool, similarity: float) -> float:
        """è¨ˆç®—å“è³ªåˆ†æ•¸"""
        base_score = 1.0 if is_delta else 0.0
        
        # è©•è«–åˆ†æ•¸ (æ¨™æº–åŒ–åˆ° 0-1)
        comment_score = max(0, min(comment.get('score', 0), 50)) / 50.0
        
        # ç›¸ä¼¼åº¦åˆ†æ•¸
        similarity_score = max(0, min(similarity, 1.0))
        
        # é•·åº¦åˆ†æ•¸ (é©ä¸­é•·åº¦ç²å¾—æ›´é«˜åˆ†æ•¸)
        text_length = len(comment.get('body', ''))
        if 50 <= text_length <= 500:
            length_score = 1.0
        elif text_length < 50:
            length_score = text_length / 50.0
        else:
            length_score = max(0.5, 1.0 - (text_length - 500) / 1000.0)
        
        # çµæ§‹åˆ†æ•¸ (åŒ…å«è«–è­‰çµæ§‹çš„è©•è«–ç²å¾—æ›´é«˜åˆ†æ•¸)
        body = comment.get('body', '').lower()
        structure_indicators = ['because', 'therefore', 'however', 'furthermore', 
                               'moreover', 'in addition', 'for example', 'studies show']
        structure_score = min(1.0, sum(1 for indicator in structure_indicators if indicator in body) / 3.0)
        
        # ç¶œåˆåˆ†æ•¸
        if is_delta:
            # Delta è©•è«–ï¼šæ›´é‡è¦–å“è³ªæŒ‡æ¨™
            final_score = (
                0.4 * base_score +
                0.25 * comment_score +
                0.15 * similarity_score +
                0.1 * length_score +
                0.1 * structure_score
            )
        else:
            # Non-delta è©•è«–ï¼šç›¸å°è¼ƒä½çš„åŸºç¤åˆ†æ•¸
            final_score = (
                0.2 * base_score +
                0.3 * comment_score +
                0.2 * similarity_score +
                0.15 * length_score +
                0.15 * structure_score
            )
        
        # ç¸®æ”¾åˆ° 0-2 ç¯„åœ
        return final_score * 2.0
    
    def extract_features(self, submission: Dict, comment: Dict) -> Dict:
        """æå–ç‰¹å¾µ"""
        # æäº¤æ–‡æœ¬
        title = submission.get('title', '')
        selftext = submission.get('selftext', '')
        submission_text = f"{title} {selftext}".strip()
        
        # è©•è«–æ–‡æœ¬
        comment_text = comment.get('body', '')
        
        # æ¸…ç†æ–‡æœ¬
        submission_text = self.clean_text(submission_text)
        comment_text = self.clean_text(comment_text)
        
        # çµ„åˆæ–‡æœ¬
        combined_text = f"Submission: {submission_text} Comment: {comment_text}"
        
        return {
            'text': combined_text,
            'submission_text': submission_text,
            'comment_text': comment_text,
            'comment_score': comment.get('score', 0),
            'submission_score': submission.get('score', 0)
        }
    
    def process_data(self) -> pd.DataFrame:
        """è™•ç†æ•¸æ“šä¸¦ç”Ÿæˆè¨“ç·´æ¨£æœ¬"""
        print(f"ğŸ“‚ è™•ç†æ•¸æ“šæ–‡ä»¶: {self.input_path}")
        
        if not self.input_path.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ•¸æ“šæ–‡ä»¶: {self.input_path}")
        
        samples = []
        valid_count = 0
        total_count = 0
        
        with open(self.input_path, 'r', encoding='utf-8') as f:
            for line in tqdm(f, desc="è™•ç†æ•¸æ“š"):
                try:
                    data = json.loads(line.strip())
                    total_count += 1
                    
                    submission = data.get('submission', {})
                    similarity = data.get('comments_similarity', 0.0)
                    
                    # è™•ç† delta è©•è«–
                    delta_comment = data.get('delta_comment')
                    if delta_comment and delta_comment.get('body'):
                        features = self.extract_features(submission, delta_comment)
                        if features['text'] and len(features['text']) > 20:
                            score = self.calculate_quality_score(
                                delta_comment, submission, True, similarity
                            )
                            
                            samples.append({
                                'text': features['text'],
                                'score': score,
                                'is_delta': True,
                                'comment_score': features['comment_score'],
                                'similarity': similarity
                            })
                            valid_count += 1
                    
                    # è™•ç† non-delta è©•è«–
                    nodelta_comment = data.get('nodelta_comment')
                    if nodelta_comment and nodelta_comment.get('body'):
                        features = self.extract_features(submission, nodelta_comment)
                        if features['text'] and len(features['text']) > 20:
                            score = self.calculate_quality_score(
                                nodelta_comment, submission, False, similarity
                            )
                            
                            samples.append({
                                'text': features['text'],
                                'score': score,
                                'is_delta': False,
                                'comment_score': features['comment_score'],
                                'similarity': similarity
                            })
                            valid_count += 1
                            
                except (json.JSONDecodeError, KeyError) as e:
                    continue
        
        print(f"ğŸ“Š æ•¸æ“šè™•ç†å®Œæˆ:")
        print(f"  ç¸½è¨˜éŒ„æ•¸: {total_count}")
        print(f"  æœ‰æ•ˆæ¨£æœ¬: {valid_count}")
        print(f"  æœ‰æ•ˆç‡: {valid_count/total_count*100:.1f}%")
        
        # è½‰æ›ç‚º DataFrame
        df = pd.DataFrame(samples)
        
        if len(df) == 0:
            raise ValueError("æ²’æœ‰ç”Ÿæˆæœ‰æ•ˆçš„è¨“ç·´æ¨£æœ¬")
        
        # æ•¸æ“šçµ±è¨ˆ
        print(f"\nğŸ“ˆ æ•¸æ“šçµ±è¨ˆ:")
        print(f"  Delta æ¨£æœ¬: {df['is_delta'].sum()} ({df['is_delta'].mean()*100:.1f}%)")
        print(f"  Non-delta æ¨£æœ¬: {(~df['is_delta']).sum()} ({(~df['is_delta']).mean()*100:.1f}%)")
        print(f"  åˆ†æ•¸ç¯„åœ: {df['score'].min():.3f} ~ {df['score'].max():.3f}")
        print(f"  å¹³å‡åˆ†æ•¸: {df['score'].mean():.3f}")
        print(f"  åˆ†æ•¸æ¨™æº–å·®: {df['score'].std():.3f}")
        
        return df
    
    def save_data(self, df: pd.DataFrame):
        """ä¿å­˜è™•ç†å¾Œçš„æ•¸æ“š"""
        print(f"ğŸ’¾ ä¿å­˜æ•¸æ“šåˆ°: {self.output_path}")
        df.to_csv(self.output_path, index=False, encoding='utf-8')
        
        # ä¿å­˜çµ±è¨ˆä¿¡æ¯
        stats_path = self.output_path.parent / "data_stats.txt"
        with open(stats_path, 'w', encoding='utf-8') as f:
            f.write("RL è¨“ç·´æ•¸æ“šçµ±è¨ˆ\n")
            f.write("=" * 30 + "\n")
            f.write(f"ç¸½æ¨£æœ¬æ•¸: {len(df)}\n")
            f.write(f"Delta æ¨£æœ¬: {df['is_delta'].sum()}\n")
            f.write(f"Non-delta æ¨£æœ¬: {(~df['is_delta']).sum()}\n")
            f.write(f"åˆ†æ•¸ç¯„åœ: {df['score'].min():.3f} ~ {df['score'].max():.3f}\n")
            f.write(f"å¹³å‡åˆ†æ•¸: {df['score'].mean():.3f}\n")
            f.write(f"åˆ†æ•¸æ¨™æº–å·®: {df['score'].std():.3f}\n")
            f.write(f"\nåˆ†æ•¸åˆ†å¸ƒ:\n")
            f.write(str(df['score'].describe()))
        
        print(f"ğŸ“Š çµ±è¨ˆä¿¡æ¯ä¿å­˜åˆ°: {stats_path}")
    
    def run(self) -> pd.DataFrame:
        """åŸ·è¡Œå®Œæ•´çš„æ•¸æ“šè™•ç†æµç¨‹"""
        print("ğŸš€ é–‹å§‹ RL æ•¸æ“šè™•ç†...")
        
        # è™•ç†æ•¸æ“š
        df = self.process_data()
        
        # ä¿å­˜æ•¸æ“š
        self.save_data(df)
        
        print("âœ… æ•¸æ“šè™•ç†å®Œæˆï¼")
        return df

def main():
    """ä¸»å‡½æ•¸"""
    processor = RLDataProcessor()
    df = processor.run()
    print(f"\nğŸ‰ æˆåŠŸç”Ÿæˆ {len(df)} å€‹è¨“ç·´æ¨£æœ¬")

if __name__ == "__main__":
    main() 
"""
é›¢ç·šæ•¸æ“šé›†æ§‹å»ºå™¨ (èˆŠç‰ˆæœ¬ï¼Œå»ºè­°ä½¿ç”¨ data_processor.py)
ä¿ç•™ç”¨æ–¼å‘å¾Œå…¼å®¹
"""

import json
import pathlib
import tqdm
import csv
from pathlib import Path
import sys

# æ·»åŠ  src è·¯å¾‘ä»¥ä¾¿å°å…¥å…¶ä»–æ¨¡çµ„
sys.path.append(str(Path(__file__).parent.parent))

try:
    from rag.retriever import CMVRetriever
except ImportError:
    print("âš ï¸  è­¦å‘Šï¼šç„¡æ³•å°å…¥ CMVRetrieverï¼Œå°‡ä½¿ç”¨ç°¡åŒ–ç‰ˆæœ¬")
    CMVRetriever = None

PAIRS = pathlib.Path("data/raw/pairs.jsonl")
OUT = pathlib.Path("data/rl/offline_rl.jsonl")

def reward(delta: bool, sim: float, score: int) -> float:
    """è¨ˆç®—çå‹µåˆ†æ•¸"""
    base = 1.0 if delta else 0.0
    topic = 0.5 * sim
    qual = 0.5 * min(score, 20) / 20
    return base + (topic + qual if delta else topic)

def simple_retrieve(query: str, k: int = 5) -> list:
    """ç°¡åŒ–ç‰ˆæª¢ç´¢å™¨ï¼Œç•¶ CMVRetriever ä¸å¯ç”¨æ™‚ä½¿ç”¨"""
    # é€™è£¡æ‡‰è©²å¯¦ç¾ç°¡å–®çš„æª¢ç´¢é‚è¼¯
    # æš«æ™‚è¿”å›ç©ºåˆ—è¡¨
    return [f"Retrieved snippet {i+1} for: {query[:50]}..." for i in range(k)]

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ æ§‹å»ºé›¢ç·š RL æ•¸æ“šé›†...")
    print("âš ï¸  æ³¨æ„ï¼šé€™æ˜¯èˆŠç‰ˆæœ¬ï¼Œå»ºè­°ä½¿ç”¨ data_processor.py")
    
    # æª¢æŸ¥è¼¸å…¥æ–‡ä»¶
    if not PAIRS.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥æ–‡ä»¶: {PAIRS}")
        print("è«‹ç¢ºä¿ data/raw/pairs.jsonl å­˜åœ¨")
        return
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    OUT.parent.mkdir(parents=True, exist_ok=True)
    
    # åˆå§‹åŒ–æª¢ç´¢å™¨
    if CMVRetriever is not None:
        try:
            retr = CMVRetriever(quality="high", k=5)
            print("âœ… CMVRetriever åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  CMVRetriever åˆå§‹åŒ–å¤±æ•—: {e}")
            print("ä½¿ç”¨ç°¡åŒ–ç‰ˆæª¢ç´¢å™¨")
            retr = None
    else:
        retr = None
    
    processed_count = 0
    success_count = 0
    
    with OUT.open("w", encoding="utf-8") as w:
        with PAIRS.open(encoding="utf-8") as f:
            for line in tqdm.tqdm(f, desc="è™•ç†æ•¸æ“šå°"):
                try:
                    p = json.loads(line.strip())
                    processed_count += 1
                    
                    sub = p.get("submission", {})
                    state = sub.get("title", "") + "\n" + sub.get("selftext", "")
                    
                    # æª¢ç´¢ç›¸é—œç‰‡æ®µ
                    if retr is not None:
                        try:
                            pool = retr.retrieve(state)
                        except:
                            pool = simple_retrieve(state)
                    else:
                        pool = simple_retrieve(state)
                    
                    if len(pool) < 5:
                        continue
                    
                    # è™•ç†æˆåŠŸæ¨£æœ¬ (delta comment)
                    dc = p.get("delta_comment")
                    if dc and dc.get("body"):
                        sim = p.get("comments_similarity", 0.0)
                        r = reward(True, sim, dc.get("score", 0))
                        
                        # æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„ç‰‡æ®µ
                        best = 0  # ç°¡åŒ–ç‰ˆæœ¬ï¼Œç¸½æ˜¯é¸æ“‡ç¬¬ä¸€å€‹
                        if isinstance(pool, list) and len(pool) > 0:
                            # å˜—è©¦æ‰¾åˆ°æœ€ç›¸é—œçš„ç‰‡æ®µ
                            dc_body = dc.get("body", "").lower()
                            for i, snippet in enumerate(pool):
                                if isinstance(snippet, str) and any(word in snippet.lower() for word in dc_body.split()[:5]):
                                    best = i
                                    break
                        
                        sample = {
                            "state": state,
                            "pool": pool,
                            "action": best,
                            "reward": r,
                            "type": "delta"
                        }
                        w.write(json.dumps(sample, ensure_ascii=False) + "\n")
                        success_count += 1
                    
                    # è™•ç†å¤±æ•—æ¨£æœ¬ (non-delta comment)
                    nc = p.get("nodelta_comment")
                    if nc and nc.get("body"):
                        sim = p.get("comments_similarity", 0.0)
                        r = reward(False, sim, nc.get("score", 0))
                        
                        sample = {
                            "state": state,
                            "pool": pool,
                            "action": 0,  # ç°¡åŒ–ç‰ˆæœ¬
                            "reward": r,
                            "type": "nodelta"
                        }
                        w.write(json.dumps(sample, ensure_ascii=False) + "\n")
                        success_count += 1
                        
                except (json.JSONDecodeError, KeyError) as e:
                    continue
                except Exception as e:
                    print(f"è™•ç†éŒ¯èª¤: {e}")
                    continue
    
    print(f"âœ… é›¢ç·šæ•¸æ“šé›†æ§‹å»ºå®Œæˆ")
    print(f"  è™•ç†è¨˜éŒ„: {processed_count}")
    print(f"  ç”Ÿæˆæ¨£æœ¬: {success_count}")
    print(f"  è¼¸å‡ºæ–‡ä»¶: {OUT}")
    print(f"  æˆåŠŸç‡: {success_count/processed_count*100:.1f}%" if processed_count > 0 else "  æˆåŠŸç‡: 0%")
    
    # ç”Ÿæˆçµ±è¨ˆä¿¡æ¯
    stats_file = OUT.parent / "offline_dataset_stats.txt"
    with open(stats_file, 'w', encoding='utf-8') as f:
        f.write("é›¢ç·š RL æ•¸æ“šé›†çµ±è¨ˆ\n")
        f.write("=" * 30 + "\n")
        f.write(f"è™•ç†è¨˜éŒ„: {processed_count}\n")
        f.write(f"ç”Ÿæˆæ¨£æœ¬: {success_count}\n")
        f.write(f"æˆåŠŸç‡: {success_count/processed_count*100:.1f}%\n" if processed_count > 0 else "æˆåŠŸç‡: 0%\n")
        f.write(f"è¼¸å‡ºæ–‡ä»¶: {OUT}\n")
    
    print(f"ğŸ“Š çµ±è¨ˆä¿¡æ¯ä¿å­˜è‡³: {stats_file}")
    
    # å»ºè­°ä½¿ç”¨æ–°ç‰ˆæœ¬
    print("\nğŸ’¡ å»ºè­°ï¼š")
    print("  æ­¤è…³æœ¬ç‚ºèˆŠç‰ˆæœ¬ï¼Œå»ºè­°ä½¿ç”¨æ–°çš„è¨“ç·´ pipelineï¼š")
    print("  python src/rl/pipeline.py")
    print("  æˆ–å–®ç¨ä½¿ç”¨æ•¸æ“šè™•ç†å™¨ï¼š")
    print("  python src/rl/data_processor.py")

if __name__ == "__main__":
    main() 
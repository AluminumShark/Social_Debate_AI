"""
RL æ¨¡å‹è©•ä¼°å™¨
è©•ä¼°è¨“ç·´å¾Œçš„ç­–ç•¥ç¶²è·¯æ€§èƒ½
"""

import pandas as pd
import numpy as np
import torch
from pathlib import Path
from typing import Dict, List, Tuple
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import json

class RLEvaluator:
    """RL æ¨¡å‹è©•ä¼°å™¨"""
    
    def __init__(self, model_path: str, test_data_path: str = None):
        self.model_path = Path(model_path)
        self.test_data_path = Path(test_data_path) if test_data_path else None
        
        # è¼‰å…¥æ¨¡å‹å’Œ tokenizer
        print(f"ğŸ“¦ è¼‰å…¥æ¨¡å‹: {self.model_path}")
        self.tokenizer = AutoTokenizer.from_pretrained(str(self.model_path))
        self.model = AutoModelForSequenceClassification.from_pretrained(str(self.model_path))
        
        # è¨­å‚™æª¢æ¸¬
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
        self.model.eval()
        
        print(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼Œä½¿ç”¨è¨­å‚™: {self.device}")
    
    def predict_batch(self, texts: List[str]) -> np.ndarray:
        """æ‰¹é‡é æ¸¬"""
        # Tokenization
        inputs = self.tokenizer(
            texts,
            truncation=True,
            padding=True,
            max_length=512,
            return_tensors="pt"
        )
        
        # ç§»åˆ°è¨­å‚™
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        # é æ¸¬
        with torch.no_grad():
            outputs = self.model(**inputs)
            predictions = outputs.logits.squeeze().cpu().numpy()
        
        # ç¢ºä¿è¿”å› 1D array
        if predictions.ndim == 0:
            predictions = np.array([predictions])
        
        return predictions
    
    def evaluate_test_set(self, test_df: pd.DataFrame = None) -> Dict:
        """è©•ä¼°æ¸¬è©¦é›†"""
        if test_df is None:
            if self.test_data_path is None:
                raise ValueError("éœ€è¦æä¾›æ¸¬è©¦æ•¸æ“š")
            test_df = pd.read_csv(self.test_data_path)
        
        print(f"ğŸ“Š è©•ä¼°æ¸¬è©¦é›†ï¼Œå…± {len(test_df)} å€‹æ¨£æœ¬")
        
        # æ‰¹é‡é æ¸¬
        predictions = self.predict_batch(test_df['text'].tolist())
        true_values = test_df['score'].values
        
        # è¨ˆç®—æŒ‡æ¨™
        mse = mean_squared_error(true_values, predictions)
        mae = mean_absolute_error(true_values, predictions)
        rmse = np.sqrt(mse)
        r2 = r2_score(true_values, predictions)
        
        # è¨ˆç®—ç›¸é—œä¿‚æ•¸
        correlation = np.corrcoef(true_values, predictions)[0, 1]
        
        results = {
            'mse': mse,
            'mae': mae,
            'rmse': rmse,
            'r2': r2,
            'correlation': correlation,
            'predictions': predictions,
            'true_values': true_values
        }
        
        print(f"ğŸ“ˆ è©•ä¼°çµæœ:")
        print(f"  MSE: {mse:.4f}")
        print(f"  MAE: {mae:.4f}")
        print(f"  RMSE: {rmse:.4f}")
        print(f"  RÂ²: {r2:.4f}")
        print(f"  ç›¸é—œä¿‚æ•¸: {correlation:.4f}")
        
        return results
    
    def analyze_by_category(self, test_df: pd.DataFrame) -> Dict:
        """æŒ‰é¡åˆ¥åˆ†ææ€§èƒ½"""
        print("ğŸ” æŒ‰é¡åˆ¥åˆ†ææ€§èƒ½...")
        
        predictions = self.predict_batch(test_df['text'].tolist())
        
        # æŒ‰ delta/non-delta åˆ†æ
        if 'is_delta' in test_df.columns:
            delta_mask = test_df['is_delta'].astype(bool)
            
            # Delta æ¨£æœ¬
            delta_true = test_df[delta_mask]['score'].values
            delta_pred = predictions[delta_mask]
            
            # Non-delta æ¨£æœ¬
            nodelta_true = test_df[~delta_mask]['score'].values
            nodelta_pred = predictions[~delta_mask]
            
            results = {
                'delta': {
                    'count': len(delta_true),
                    'mse': mean_squared_error(delta_true, delta_pred),
                    'mae': mean_absolute_error(delta_true, delta_pred),
                    'r2': r2_score(delta_true, delta_pred),
                    'correlation': np.corrcoef(delta_true, delta_pred)[0, 1] if len(delta_true) > 1 else 0
                },
                'nodelta': {
                    'count': len(nodelta_true),
                    'mse': mean_squared_error(nodelta_true, nodelta_pred),
                    'mae': mean_absolute_error(nodelta_true, nodelta_pred),
                    'r2': r2_score(nodelta_true, nodelta_pred),
                    'correlation': np.corrcoef(nodelta_true, nodelta_pred)[0, 1] if len(nodelta_true) > 1 else 0
                }
            }
            
            print(f"  Delta æ¨£æœ¬ ({results['delta']['count']} å€‹):")
            print(f"    MSE: {results['delta']['mse']:.4f}")
            print(f"    RÂ²: {results['delta']['r2']:.4f}")
            
            print(f"  Non-delta æ¨£æœ¬ ({results['nodelta']['count']} å€‹):")
            print(f"    MSE: {results['nodelta']['mse']:.4f}")
            print(f"    RÂ²: {results['nodelta']['r2']:.4f}")
            
            return results
        
        return {}
    
    def plot_results(self, results: Dict, save_path: str = None):
        """ç¹ªè£½è©•ä¼°çµæœåœ–è¡¨"""
        predictions = results['predictions']
        true_values = results['true_values']
        
        # è¨­ç½®ä¸­æ–‡å­—é«”
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # 1. çœŸå¯¦å€¼ vs é æ¸¬å€¼æ•£é»åœ–
        axes[0, 0].scatter(true_values, predictions, alpha=0.6)
        axes[0, 0].plot([true_values.min(), true_values.max()], 
                       [true_values.min(), true_values.max()], 'r--', lw=2)
        axes[0, 0].set_xlabel('çœŸå¯¦å€¼')
        axes[0, 0].set_ylabel('é æ¸¬å€¼')
        axes[0, 0].set_title(f'çœŸå¯¦å€¼ vs é æ¸¬å€¼ (RÂ² = {results["r2"]:.3f})')
        
        # 2. æ®˜å·®åœ–
        residuals = true_values - predictions
        axes[0, 1].scatter(predictions, residuals, alpha=0.6)
        axes[0, 1].axhline(y=0, color='r', linestyle='--')
        axes[0, 1].set_xlabel('é æ¸¬å€¼')
        axes[0, 1].set_ylabel('æ®˜å·®')
        axes[0, 1].set_title('æ®˜å·®åœ–')
        
        # 3. é æ¸¬å€¼åˆ†å¸ƒ
        axes[1, 0].hist(predictions, bins=30, alpha=0.7, label='é æ¸¬å€¼')
        axes[1, 0].hist(true_values, bins=30, alpha=0.7, label='çœŸå¯¦å€¼')
        axes[1, 0].set_xlabel('åˆ†æ•¸')
        axes[1, 0].set_ylabel('é »ç‡')
        axes[1, 0].set_title('åˆ†æ•¸åˆ†å¸ƒæ¯”è¼ƒ')
        axes[1, 0].legend()
        
        # 4. èª¤å·®åˆ†å¸ƒ
        errors = np.abs(residuals)
        axes[1, 1].hist(errors, bins=30, alpha=0.7)
        axes[1, 1].set_xlabel('çµ•å°èª¤å·®')
        axes[1, 1].set_ylabel('é »ç‡')
        axes[1, 1].set_title(f'çµ•å°èª¤å·®åˆ†å¸ƒ (MAE = {results["mae"]:.3f})')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š åœ–è¡¨ä¿å­˜è‡³: {save_path}")
        else:
            plt.show()
        
        plt.close()
    
    def test_policy_functions(self) -> Dict:
        """æ¸¬è©¦ç­–ç•¥åŠŸèƒ½"""
        print("ğŸ§ª æ¸¬è©¦ç­–ç•¥åŠŸèƒ½...")
        
        from policy_network import PolicyNetwork, choose_snippet
        
        # å‰µå»ºç­–ç•¥ç¶²è·¯
        policy_net = PolicyNetwork(model_path=str(self.model_path))
        
        # æ¸¬è©¦æ¡ˆä¾‹
        test_cases = [
            {
                'query': 'Should we implement universal healthcare?',
                'pool': [
                    {'content': 'Universal healthcare reduces costs and improves access', 'similarity_score': 0.9},
                    {'content': 'Private healthcare offers better quality', 'similarity_score': 0.7},
                    {'content': 'Healthcare is a human right', 'similarity_score': 0.8}
                ]
            },
            {
                'query': 'Is climate change caused by human activities?',
                'pool': [
                    {'content': 'Scientific consensus supports human-caused climate change', 'similarity_score': 0.95},
                    {'content': 'Natural climate variation exists', 'similarity_score': 0.6},
                    {'content': 'Carbon emissions are the main driver', 'similarity_score': 0.85}
                ]
            }
        ]
        
        results = []
        
        for i, case in enumerate(test_cases):
            print(f"\næ¸¬è©¦æ¡ˆä¾‹ {i+1}: {case['query'][:50]}...")
            
            # ç­–ç•¥é¸æ“‡
            strategy = policy_net.select_strategy(case['query'])
            
            # å“è³ªé æ¸¬
            quality = policy_net.predict_quality(case['query'])
            
            # ç‰‡æ®µé¸æ“‡
            chosen_snippet = choose_snippet(case['query'], case['pool'], policy_net)
            
            result = {
                'query': case['query'],
                'strategy': strategy,
                'quality': quality,
                'chosen_snippet': chosen_snippet[:100] + '...' if len(chosen_snippet) > 100 else chosen_snippet
            }
            
            results.append(result)
            
            print(f"  ç­–ç•¥: {strategy}")
            print(f"  å“è³ªåˆ†æ•¸: {quality:.3f}")
            print(f"  é¸æ“‡ç‰‡æ®µ: {result['chosen_snippet']}")
        
        return results
    
    def generate_report(self, output_dir: str = None) -> str:
        """ç”Ÿæˆè©•ä¼°å ±å‘Š"""
        if output_dir is None:
            output_dir = self.model_path.parent / "evaluation"
        else:
            output_dir = Path(output_dir)
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“ ç”Ÿæˆè©•ä¼°å ±å‘Š...")
        
        # è¼‰å…¥æ¸¬è©¦æ•¸æ“š
        test_data_path = self.model_path.parent.parent / "rl" / "rl_pairs.csv"
        if test_data_path.exists():
            df = pd.read_csv(test_data_path)
            # ä½¿ç”¨ 20% ä½œç‚ºæ¸¬è©¦é›†
            test_df = df.sample(frac=0.2, random_state=42)
        else:
            print("âš ï¸  æ‰¾ä¸åˆ°æ¸¬è©¦æ•¸æ“šï¼Œè·³éæ•¸å€¼è©•ä¼°")
            test_df = None
        
        report_data = {
            'model_path': str(self.model_path),
            'evaluation_time': pd.Timestamp.now().isoformat(),
            'device': str(self.device)
        }
        
        # æ•¸å€¼è©•ä¼°
        if test_df is not None:
            eval_results = self.evaluate_test_set(test_df)
            report_data['numerical_evaluation'] = {
                'test_samples': len(test_df),
                'mse': float(eval_results['mse']),
                'mae': float(eval_results['mae']),
                'rmse': float(eval_results['rmse']),
                'r2': float(eval_results['r2']),
                'correlation': float(eval_results['correlation'])
            }
            
            # æŒ‰é¡åˆ¥åˆ†æ
            category_results = self.analyze_by_category(test_df)
            if category_results:
                report_data['category_analysis'] = category_results
            
            # ç¹ªè£½åœ–è¡¨
            plot_path = output_dir / "evaluation_plots.png"
            self.plot_results(eval_results, str(plot_path))
        
        # åŠŸèƒ½æ¸¬è©¦
        policy_results = self.test_policy_functions()
        report_data['policy_function_tests'] = policy_results
        
        # ä¿å­˜å ±å‘Š
        report_path = output_dir / "evaluation_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆæ–‡æœ¬å ±å‘Š
        text_report_path = output_dir / "evaluation_summary.txt"
        with open(text_report_path, 'w', encoding='utf-8') as f:
            f.write("RL æ¨¡å‹è©•ä¼°å ±å‘Š\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"æ¨¡å‹è·¯å¾‘: {self.model_path}\n")
            f.write(f"è©•ä¼°æ™‚é–“: {report_data['evaluation_time']}\n")
            f.write(f"ä½¿ç”¨è¨­å‚™: {report_data['device']}\n\n")
            
            if 'numerical_evaluation' in report_data:
                eval_data = report_data['numerical_evaluation']
                f.write("æ•¸å€¼è©•ä¼°çµæœ:\n")
                f.write("-" * 30 + "\n")
                f.write(f"æ¸¬è©¦æ¨£æœ¬æ•¸: {eval_data['test_samples']}\n")
                f.write(f"MSE: {eval_data['mse']:.4f}\n")
                f.write(f"MAE: {eval_data['mae']:.4f}\n")
                f.write(f"RMSE: {eval_data['rmse']:.4f}\n")
                f.write(f"RÂ²: {eval_data['r2']:.4f}\n")
                f.write(f"ç›¸é—œä¿‚æ•¸: {eval_data['correlation']:.4f}\n\n")
            
            f.write("ç­–ç•¥åŠŸèƒ½æ¸¬è©¦:\n")
            f.write("-" * 30 + "\n")
            for i, result in enumerate(policy_results):
                f.write(f"æ¸¬è©¦ {i+1}:\n")
                f.write(f"  æŸ¥è©¢: {result['query']}\n")
                f.write(f"  ç­–ç•¥: {result['strategy']}\n")
                f.write(f"  å“è³ªåˆ†æ•¸: {result['quality']:.3f}\n")
                f.write(f"  é¸æ“‡ç‰‡æ®µ: {result['chosen_snippet']}\n\n")
        
        print(f"âœ… è©•ä¼°å ±å‘Šç”Ÿæˆå®Œæˆ:")
        print(f"  JSON å ±å‘Š: {report_path}")
        print(f"  æ–‡æœ¬æ‘˜è¦: {text_report_path}")
        if test_df is not None:
            print(f"  åœ–è¡¨: {plot_path}")
        
        return str(report_path)

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="RL æ¨¡å‹è©•ä¼°å™¨")
    parser.add_argument("--model", required=True, help="æ¨¡å‹è·¯å¾‘")
    parser.add_argument("--test-data", help="æ¸¬è©¦æ•¸æ“šè·¯å¾‘")
    parser.add_argument("--output", help="è¼¸å‡ºç›®éŒ„")
    
    args = parser.parse_args()
    
    evaluator = RLEvaluator(args.model, args.test_data)
    report_path = evaluator.generate_report(args.output)
    
    print(f"\nğŸ‰ è©•ä¼°å®Œæˆï¼Œå ±å‘Šä¿å­˜è‡³: {report_path}")

if __name__ == "__main__":
    main() 
"""
RL Pipeline æ¸¬è©¦è…³æœ¬
ç”¨æ–¼æ¸¬è©¦ RL è¨“ç·´ pipeline çš„å„å€‹çµ„ä»¶
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np

# æ·»åŠ  src è·¯å¾‘
sys.path.append(str(Path(__file__).parent / "src"))

def test_data_processor():
    """æ¸¬è©¦æ•¸æ“šè™•ç†å™¨"""
    print("ğŸ§ª æ¸¬è©¦æ•¸æ“šè™•ç†å™¨...")
    
    try:
        from rl.data_processor import RLDataProcessor
        
        # å‰µå»ºæ¸¬è©¦æ•¸æ“š
        test_data = [
            {
                "submission": {
                    "title": "Test submission title",
                    "selftext": "Test submission content"
                },
                "delta_comment": {
                    "body": "This is a convincing argument because it provides evidence",
                    "score": 10
                },
                "nodelta_comment": {
                    "body": "I disagree but this is not convincing",
                    "score": 2
                },
                "comments_similarity": 0.8
            }
        ]
        
        # å‰µå»ºè‡¨æ™‚æ¸¬è©¦æ–‡ä»¶
        import json
        test_file = Path("test_data.jsonl")
        with open(test_file, 'w', encoding='utf-8') as f:
            for item in test_data:
                f.write(json.dumps(item) + '\n')
        
        # æ¸¬è©¦è™•ç†å™¨
        processor = RLDataProcessor(
            input_path=str(test_file),
            output_path="test_output.csv"
        )
        
        df = processor.run()
        
        # æª¢æŸ¥çµæœ
        assert len(df) > 0, "æ‡‰è©²ç”Ÿæˆè‡³å°‘ä¸€å€‹æ¨£æœ¬"
        assert 'text' in df.columns, "æ‡‰è©²åŒ…å« text åˆ—"
        assert 'score' in df.columns, "æ‡‰è©²åŒ…å« score åˆ—"
        
        # æ¸…ç†
        test_file.unlink()
        Path("test_output.csv").unlink(missing_ok=True)
        Path("data/rl/data_stats.txt").unlink(missing_ok=True)
        
        print("âœ… æ•¸æ“šè™•ç†å™¨æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ æ•¸æ“šè™•ç†å™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_policy_network():
    """æ¸¬è©¦ç­–ç•¥ç¶²è·¯"""
    print("ğŸ§ª æ¸¬è©¦ç­–ç•¥ç¶²è·¯...")
    
    try:
        from rl.policy_network import PolicyNetwork, choose_snippet
        
        # å‰µå»ºæ¸¬è©¦ç”¨çš„ç­–ç•¥ç¶²è·¯ï¼ˆä¸è¼‰å…¥çœŸå¯¦æ¨¡å‹ï¼‰
        class MockPolicyNetwork:
            def select_strategy(self, query):
                return "analytical"
            
            def predict_quality(self, text):
                return 0.75
            
            def encode_text(self, text):
                return np.random.rand(768)
        
        mock_policy = MockPolicyNetwork()
        
        # æ¸¬è©¦ç­–ç•¥é¸æ“‡
        strategy = mock_policy.select_strategy("Test query")
        assert strategy in ["analytical", "aggressive", "defensive", "empathetic"], f"ç„¡æ•ˆç­–ç•¥: {strategy}"
        
        # æ¸¬è©¦å“è³ªé æ¸¬
        quality = mock_policy.predict_quality("Test text")
        assert 0 <= quality <= 2, f"å“è³ªåˆ†æ•¸è¶…å‡ºç¯„åœ: {quality}"
        
        # æ¸¬è©¦ç‰‡æ®µé¸æ“‡
        test_pool = [
            {'content': 'First snippet', 'similarity_score': 0.8},
            {'content': 'Second snippet', 'similarity_score': 0.6}
        ]
        
        # ä½¿ç”¨ç°¡åŒ–ç‰ˆæœ¬çš„ choose_snippet
        def simple_choose_snippet(query, pool, policy_net):
            # ç°¡å–®é¸æ“‡æœ€é«˜ç›¸ä¼¼åº¦çš„ç‰‡æ®µ
            best_snippet = max(pool, key=lambda x: x['similarity_score'])
            return best_snippet['content']
        
        chosen = simple_choose_snippet("test query", test_pool, mock_policy)
        assert chosen == 'First snippet', f"æ‡‰è©²é¸æ“‡æœ€é«˜ç›¸ä¼¼åº¦çš„ç‰‡æ®µ"
        
        print("âœ… ç­–ç•¥ç¶²è·¯æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ ç­–ç•¥ç¶²è·¯æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_trainer_setup():
    """æ¸¬è©¦è¨“ç·´å™¨è¨­ç½®"""
    print("ğŸ§ª æ¸¬è©¦è¨“ç·´å™¨è¨­ç½®...")
    
    try:
        from rl.trainer import RLTrainer
        
        # å‰µå»ºæ¸¬è©¦æ•¸æ“š
        test_df = pd.DataFrame({
            'text': ['Test text 1', 'Test text 2', 'Test text 3'],
            'score': [1.0, 0.5, 1.5]
        })
        
        test_df.to_csv('test_training_data.csv', index=False)
        
        # æ¸¬è©¦è¨“ç·´å™¨åˆå§‹åŒ–
        trainer = RLTrainer(
            data_path='test_training_data.csv',
            output_dir='test_model_output'
        )
        
        # æ¸¬è©¦æ•¸æ“šè¼‰å…¥
        df = trainer.load_data()
        assert len(df) == 3, "æ‡‰è©²è¼‰å…¥3å€‹æ¨£æœ¬"
        
        # æ¸¬è©¦æ•¸æ“šé›†æº–å‚™
        datasets = trainer.prepare_datasets(df)
        assert 'train' in datasets, "æ‡‰è©²åŒ…å«è¨“ç·´é›†"
        assert 'test' in datasets, "æ‡‰è©²åŒ…å«æ¸¬è©¦é›†"
        
        # æ¸…ç†
        Path('test_training_data.csv').unlink()
        
        print("âœ… è¨“ç·´å™¨è¨­ç½®æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ è¨“ç·´å™¨è¨­ç½®æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_pipeline_setup():
    """æ¸¬è©¦ pipeline è¨­ç½®"""
    print("ğŸ§ª æ¸¬è©¦ pipeline è¨­ç½®...")
    
    try:
        from rl.pipeline import RLPipeline
        
        # æ¸¬è©¦ pipeline åˆå§‹åŒ–
        pipeline = RLPipeline(
            input_data="test_input.jsonl",
            processed_data="test_processed.csv",
            model_output="test_model",
            force_reprocess=True
        )
        
        # æª¢æŸ¥è·¯å¾‘è¨­ç½®
        assert pipeline.input_data.name == "test_input.jsonl"
        assert pipeline.processed_data.name == "test_processed.csv"
        assert pipeline.model_output.name == "test_model"
        assert pipeline.force_reprocess == True
        
        print("âœ… Pipeline è¨­ç½®æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ Pipeline è¨­ç½®æ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹ RL Pipeline æ¸¬è©¦")
    print("=" * 50)
    
    tests = [
        ("æ•¸æ“šè™•ç†å™¨", test_data_processor),
        ("ç­–ç•¥ç¶²è·¯", test_policy_network),
        ("è¨“ç·´å™¨è¨­ç½®", test_trainer_setup),
        ("Pipeline è¨­ç½®", test_pipeline_setup)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ“‹ æ¸¬è©¦: {test_name}")
        if test_func():
            passed += 1
        else:
            print(f"âš ï¸  {test_name} æ¸¬è©¦å¤±æ•—")
    
    print("\n" + "=" * 50)
    print(f"ğŸ¯ æ¸¬è©¦çµæœ: {passed}/{total} é€šé")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼RL Pipeline æº–å‚™å°±ç·’")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("  1. æº–å‚™è¨“ç·´æ•¸æ“š: data/raw/pairs.jsonl")
        print("  2. é‹è¡Œå®Œæ•´ pipeline: python src/rl/pipeline.py")
        print("  3. è©•ä¼°è¨“ç·´çµæœ: python src/rl/evaluator.py --model data/models/policy")
    else:
        print("âŒ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç›¸é—œçµ„ä»¶")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 